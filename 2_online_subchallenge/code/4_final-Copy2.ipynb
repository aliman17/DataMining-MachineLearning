{
 "metadata": {
  "name": "",
  "signature": "sha256:10172f002301e7194f8b739e3f720abe20626793e61a31fa19087be72029c775"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import\n",
      "from collections import defaultdict\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "import pylab as P\n",
      "import Orange\n",
      "from sklearn import decomposition\n",
      "from sklearn import linear_model\n",
      "from sklearn import ensemble\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "import scipy\n",
      "import math\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stringTOfloat(matrix):\n",
      "    \"\"\"Cast string values of a matrix into float values\"\"\"\n",
      "    matrix1 = []\n",
      "    for pos in range(len(matrix)):\n",
      "        i = matrix[pos]\n",
      "        #i[i == ''] = 0.0\n",
      "        i = i.astype(np.float)\n",
      "        matrix1.append(i)\n",
      "    return np.array( matrix1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def NANto0(matrix):\n",
      "    # Daj vse NAN na 0 -> ni ok, ampak za zacetek bo ok\n",
      "    for i in range(len(matrix)):\n",
      "        for j in range(len(matrix[i])):\n",
      "            if np.isnan(matrix[i,j]):\n",
      "                matrix[i,j] = 0\n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(name):\n",
      "    file1 = open(name, \"rU\" )\n",
      "    Y = []\n",
      "    for aRow in file1:\n",
      "        Y.append(aRow.split('\\t'))\n",
      "    file1.close()\n",
      "    return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse dilution and get denominator\n",
      "def get_dilution_denominator( string ):\n",
      "    i = 0\n",
      "    # Get rid of numerator\n",
      "    while ( string[i] != '/' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Get rid of '/'\n",
      "    while ( string[i] != '1' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Count zeros in denominator\n",
      "    n_zeros = 0\n",
      "    for j in range(i, len(string)):\n",
      "        if string[j] == '0':\n",
      "            n_zeros += 1\n",
      "            \n",
      "    return 10**n_zeros "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getX():\n",
      "    X = getData(\"../data/molecular_descriptors_data.txt\")\n",
      "    \n",
      "    # remove header\n",
      "    X = np.array(X[1:])\n",
      "    X = stringTOfloat(X)\n",
      "    # set Nan to 0\n",
      "    X = NANto0(X)\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getY():\n",
      "    Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "    \n",
      "    # header\n",
      "    head = Y[0]\n",
      "    \n",
      "    # remove header\n",
      "    Y = np.array(Y[1:])\n",
      "    \n",
      "    # get CID, get dil\n",
      "    cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "    dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "   \n",
      "    # from \n",
      "    Y_rest = np.array(Y[:, 6:]) \n",
      "    Y_rest = stringTOfloat(Y_rest)\n",
      "    \n",
      "    Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "    Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      " \n",
      "    \n",
      "    return Y_cid_dil_rest, head\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avg_median(Y_cid_dil_rest):\n",
      "    \n",
      "    cids = Y_cid_dil_rest[:, 0]\n",
      "    dils = Y_cid_dil_rest[:, 1]\n",
      "    # average\n",
      "    # get cids\n",
      "    cids_unique = np.unique(np.array(cids))\n",
      "    \n",
      "    # for each cid store avg value for all attributes\n",
      "    cid_avg = []\n",
      "    for cid in cids_unique:\n",
      "        cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "        dil_low = cid_samples[0][1] \n",
      "        dil_high = cid_samples[1][1] \n",
      "        cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil        \n",
      "        # average\n",
      "        avg_low = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest[0::2].T]\n",
      "        avg_high = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest[1::2].T]\n",
      "        # concatenate cid with average values\n",
      "        cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "        cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "        \n",
      "    cid_avg = np.array( cid_avg )\n",
      "    return cid_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPredict():\n",
      "    P = getData(\"../data/predict.txt\")\n",
      "    \n",
      "    P = np.array(P)\n",
      "    \n",
      "    # get CID\n",
      "    cids = stringTOfloat(P[:,0])\n",
      "    dils = [get_dilution_denominator(dil) for dil in P[:,1]]\n",
      "    \n",
      "    P = []\n",
      "    for i in range( len(cids) ):\n",
      "        P.append((cids[i], dils[i]))\n",
      "    return np.array(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pravzaprav, ne uporabljam\n",
      "def normalize_correct(matrix):\n",
      "    size = matrix.shape\n",
      "    for i in range( size[1] ):\n",
      "        sum = 0\n",
      "        n = 0\n",
      "        # Get sum of column\n",
      "        for j in range( size[0] ):\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                pass\n",
      "            else:\n",
      "                sum += abs(matrix[j,i])\n",
      "                n += 1\n",
      "          \n",
      "        # Correct each value in column\n",
      "        for j in range( size[0] ):\n",
      "            # NaN -> avg value\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                matrix[j,i] = sum / n\n",
      "                \n",
      "            # sum = 0 -> 0\n",
      "            elif sum == 0:\n",
      "                matrix[j,i] = 0\n",
      "                \n",
      "            # else value / sum\n",
      "            else:\n",
      "                matrix[j,i] = matrix[j,i] / sum\n",
      "                \n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_by_cid_and_dilution(Y, dilution = None):\n",
      "    \"\"\"Compute average attributes for CID. Dilution influences, which samples to take.\"\"\"\n",
      "    \n",
      "    if dilution != None:\n",
      "        # if dilution not None, take only samples with that dilution\n",
      "        return Y[Y[:,1] == dilution]\n",
      "    else:\n",
      "        # if None, then take all Y\n",
      "        return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_by_cid_and_low_high_dilution(Y, high=True):\n",
      "    \"\"\"Compute average attributes for CID. Based on high or low\"\"\"\n",
      "    # average for each cid and dilution\n",
      "    \n",
      "    if high:\n",
      "        return Y[1::2]  # take high dilutions\n",
      "    else:\n",
      "        return Y[0::2]  # take low dilutions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_X_Y_train(X_dict, Y):    \n",
      "    # connect them together\n",
      "    X_train = []\n",
      "    Y_train = np.array( cid_avg[:, 1:] )\n",
      "    for cid in Y[:, 0]:\n",
      "        X_train.append((X_dict[cid]))\n",
      "    X_train = np.array( X_train )\n",
      "    return X_train, Y_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ne uporabljam\n",
      "def best_model(X_train, Y_train):\n",
      "    best_m = None\n",
      "    best_val = 100\n",
      "    best_alpha = 0\n",
      "    best_ratio = 0\n",
      "    for alpha in [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10]:\n",
      "        for ratio in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
      "            elastic = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio, max_iter=500)\n",
      "            rez = my_cross_validation(X_train, Y_train, elastic)\n",
      "            if rez < best_val:\n",
      "                best_m = elastic\n",
      "                best_val = rez\n",
      "                best_alpha = alpha\n",
      "                best_ratio = ratio\n",
      "    # return best model\n",
      "    return best_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file(cid_preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../rezults/'+name+'.txt','w')\n",
      "    for cid, pred in cid_preds:\n",
      "        for i in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[i])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[i]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file2(cids, preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../rezults/'+name+'.txt','w')\n",
      "    for i in range(len(cids)):\n",
      "        cid = cids[i]\n",
      "        pred = preds[i]\n",
      "        for i in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[i])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[i]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NORM_STD = [ 0.18, 0.16, 0.06 ] #an average of normalizatin_costs outputs)\n",
      "#means were 0 (as expected for Pearson correlation)\n",
      "\n",
      "def pearson(x,y):\n",
      "    x,y = np.array(x), np.array(y)\n",
      "    anynan = np.logical_or(np.isnan(x), np.isnan(y))\n",
      "    r = scipy.stats.pearsonr(x[~anynan],y[~anynan])[0]\n",
      "    return 0. if math.isnan(r) else r\n",
      "\n",
      "def final_score(rs):\n",
      "    zs = rs/NORM_STD\n",
      "    return np.mean(zs)\n",
      "\n",
      "def evaluate_r(prediction, real):\n",
      "    userscores = prediction\n",
      "    realscores = real\n",
      "    rint = pearson(userscores[:,0], realscores[:,0])\n",
      "    rval = pearson(userscores[:,1], realscores[:,1])\n",
      "    rdecall = [ pearson(userscores[:,i], realscores[:,i]) for i in range(2,21) ]\n",
      "    rdec = np.mean(rdecall)\n",
      "    return np.array([rint, rval, rdec])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pca(X_sel_tr, components):\n",
      "    pca = decomposition.PCA(n_components=components)\n",
      "    pca.fit(X_sel_tr)\n",
      "    X_sel_tr = pca.transform(X_sel_tr)\n",
      "    return X_sel_tr, pca"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def standardize(X_sel_tr):\n",
      "    scaler = preprocessing.StandardScaler()\n",
      "    scaler.fit(X_sel_tr) #shranimo transformacijo\n",
      "    X_sel_tr = scaler.transform(X_sel_tr) #transformiramo X (standardiziramo)\n",
      "    return X_sel_tr, scaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_models(X_sel_tr, Y_train, dilution):\n",
      "    \"\"\"Create scalar, pca and 21 models for a given dilution\"\"\"\n",
      "\n",
      "    #model = linear_model.RidgeCV()\n",
      "    #model = linear_model.ElasticNetCV()\n",
      "    model = ensemble.RandomForestRegressor(n_estimators=50, max_depth=None, min_samples_split=5, random_state=0, n_jobs=1)\n",
      "    \n",
      "    models_list = []\n",
      "    for i in range(0,(Y_train.shape)[1]):\n",
      "        #print('start learn', i)\n",
      "        # learn\n",
      "        lrn = model.fit(X_sel_tr, Y_train[:, i])\n",
      "        models_list += [lrn]\n",
      "    \n",
      "    return models_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RUN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PO\u017dENI 1\n",
      "# cid, rest\n",
      "X_cid_rest = getX()\n",
      "# cid, dilution, rest\n",
      "Y_cid_dil_rest, head = getY()\n",
      "# predict info\n",
      "toPredict = getPredict()\n",
      "# Create access to chemical informations via CID\n",
      "X_dict_by_cid = dict([(i[0], i[1:]) for i in X_cid_rest])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_cid_dil_rest.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "(27244, 23)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Average\n",
      "Y_cid_dil_rest_avg = avg_median(Y_cid_dil_rest)\n",
      "# Unique dillutions\n",
      "unique_dils = np.unique(Y_cid_dil_rest[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = Y_cid_dil_rest_avg\n",
      "\n",
      "dils_predict = dict()\n",
      "for dil in unique_dils:\n",
      "    \n",
      "    # Get y for intensity and pleasantness\n",
      "    Y_int_ple = Y[ Y[:,1] == 1000]\n",
      "    # Get for rest\n",
      "    Y_rest = average_by_cid_and_low_high_dilution(Y, high=True)\n",
      "    \n",
      "    \n",
      "    #Y_cid_dil_rest_avg = average_by_cid_and_dilution(Y_cid_dil_rest, dil)\n",
      "    #Y_cid_avg = average_by_cid_and_low_high_dilution(Y_cid_dil_rest, high=True)\n",
      "    \n",
      "    #y_train = Y_cid_dil_rest_avg[:, 2:]  # remove cid and dilution, take rest\n",
      "    \n",
      "    # Pripravi X glede na Y\n",
      "    X_int_ple = np.array( [X_dict_by_cid[cid] for cid in Y_int_ple[:, 0] ] )\n",
      "    X_rest = np.array( [X_dict_by_cid[cid] for cid in Y_rest[:, 0] ] )\n",
      "    \n",
      "    Y_int_ple = Y_int_ple[:, 2:4]  # remove rest\n",
      "    Y_rest = Y_rest[:, 4:]   # remove rest\n",
      "\n",
      "    # Standardize\n",
      "    #X_int_ple, scalar_int_ple = standardize(X_int_ple)\n",
      "    #X_rest, scalar_rest = standardize(X_rest)\n",
      "    \n",
      "    # Pca\n",
      "    X_int_ple, pca_int_ple = get_pca(X_int_ple, 20)\n",
      "    X_rest, pca_rest = get_pca(X_rest, 20)\n",
      "    \n",
      "    # Get models\n",
      "    models_list_int_ple = compute_models(X_int_ple, Y_int_ple, dil)\n",
      "    models_list_rest = compute_models(X_rest, Y_rest, dil)\n",
      "    \n",
      "    models_list = models_list_int_ple + models_list_rest\n",
      "    \n",
      "    dils_predict[int(dil)] = (pca_int_ple, pca_rest, models_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-23-5acaefd1b012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Get models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmodels_list_int_ple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_int_ple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_int_ple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mmodels_list_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_rest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_rest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mmodels_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels_list_int_ple\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodels_list_rest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-20-ed950fc4b54d>\u001b[0m in \u001b[0;36mcompute_models\u001b[1;34m(X_sel_tr, Y_train, dilution)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#print('start learn', i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mlrn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_sel_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mmodels_list\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlrn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                 verbose=self.verbose)\n\u001b[1;32m--> 279\u001b[1;33m             for i in range(n_jobs))\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \"\"\"\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(trees, forest, X, y, sample_weight, verbose)\u001b[0m\n\u001b[0;32m     87\u001b[0m             tree.fit(X, y,\n\u001b[0;32m     88\u001b[0m                      \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                      check_input=False)\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_counts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([X_dict_by_cid[cid] for cid in Y[:,0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CROSS VALIDATION, izpise vmesni prediction, na koncu pa SCORE\n",
      "# Pripravi Y v odvisnosti od vhoda cid in dilutiona\n",
      "\n",
      "# Razbijemo glavno mnozico, ucno mnozico\n",
      "def CV(X, Y, cids, dils):\n",
      "    repetitions = 3\n",
      "    S = 0\n",
      "    kf = cross_validation.KFold(len(Y), n_folds=repetitions)\n",
      "    store_predictions = []\n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_cid_dil_rest_train, Y_cid_dil_rest_test = Y[train_index], Y[test_index]\n",
      "\n",
      "        # prepare examples to predict\n",
      "        toPredict = [(Y_cid_dil_rest_test[i, 0], Y_cid_dil_rest_test[i, 1]) for i in range((Y_cid_dil_rest_test.shape)[0])]\n",
      "\n",
      "        for pr in toPredict:\n",
      "            cid = pr[0]\n",
      "            dil = pr[1]\n",
      "\n",
      "            X_to_predict = X_dict_by_cid[cid]        \n",
      "            pca_int_ple, pca_rest, models_list = dils_predict[int(dil)]\n",
      "\n",
      "            #X_to_predict = scalar.transform(X_to_predict)\n",
      "            X_to_predict_int_ple = pca_int_ple.transform(X_to_predict)\n",
      "            X_to_predict_rest = pca_rest.transform(X_to_predict)\n",
      "\n",
      "            rezult = []\n",
      "            for i in range(len(models_list)):\n",
      "                model = models_list[i]\n",
      "                if i < 2:\n",
      "                    X_to_predict = X_to_predict_int_ple\n",
      "                else:\n",
      "                    X_to_predict = X_to_predict_rest\n",
      "\n",
      "                p = model.predict(X_to_predict)\n",
      "                rezult += [p[0]]\n",
      "            store_predictions += [np.array(rezult)]\n",
      "\n",
      "        store_predictions = np.array(store_predictions)\n",
      "\n",
      "        # evaluate\n",
      "        score = evaluate_r(store_predictions, Y_cid_dil_rest_test)\n",
      "        score = final_score(score)\n",
      "        print(\"Vmesni .................\", score)\n",
      "        S += score\n",
      "\n",
      "    print(\"FINAL .................\", S/repetitions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vmesni ................. -0.667492793948\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.3193097353\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0836304193093\n",
        "FINAL ................. -0.30105736998\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.31877779176"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "1.31877779176"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_to_file(cid_preds, head, 'forest_2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "elasticCV = 1.06\n",
      "ridge = 2.04792 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def RFR():\n",
      "    global X_dict_by_cid, toPredict, Y_cid_dil_rest_avg\n",
      "    X = []\n",
      "    for cid, dil in toPredict:\n",
      "        X_line = X_dict_by_cid[cid]\n",
      "        X += [X_line]\n",
      "    X = np.array(X)\n",
      "\n",
      "    X_train = []\n",
      "    for cid in Y[:, 0]:\n",
      "        X_line = X_dict_by_cid[cid]\n",
      "        X_train += [X_line]\n",
      "    X_train = np.array(X_train)\n",
      "    \n",
      "    model = ensemble.RandomForestRegressor(n_estimators=200, max_depth=None, min_samples_split=5, random_state=0, n_jobs=1)\n",
      "    model.fit(X_train, Y_cid_dil_rest_avg[:,2:])\n",
      "    P = model.predict(X)\n",
      "    return P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfp = RFR()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfp.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(80, 22)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_to_file2(toPredict[:, 0], rfp, head, \"forest_whole_3_with_dil\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-28-104fb9afe01b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwrite_to_file2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoPredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"forest_whole_3_with_dil\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-27-bca6a3d6ebce>\u001b[0m in \u001b[0;36mwrite_to_file2\u001b[1;34m(cids, preds, head, name)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# change float to int then to string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stack_v(listOfArrays):\n",
      "    M = listOfArrays[0]\n",
      "    for i in range(1,len(listOfArrays)):\n",
      "        M = np.vstack((M, listOfArrays[i]))\n",
      "    return M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def precno_preverjanje(X, Y, fold, n):\n",
      "    foldsX = np.array(np.array_split(X, fold))\n",
      "    foldsY = np.array(np.array_split(Y, fold))\n",
      "    scores = np.zeros(fold)\n",
      "    for i in range(fold):\n",
      "        indeksi = np.arange(0,fold)\n",
      "        indeksi = indeksi != i\n",
      "        Xucna = stack_v(foldsX[indeksi])\n",
      "        Yucna = stack_v(foldsY[indeksi])\n",
      "        Xtestna = foldsX[i]\n",
      "        Ytestna = foldsY[i]\n",
      "        clf = ensemble.RandomForestRegressor(n_estimators=n, n_jobs=-1)\n",
      "        clf.fit(Xucna, Yucna)\n",
      "        napoved = clf.predict(Xtestna)\n",
      "        score = final_score(evaluate_r(napoved, Ytestna))\n",
      "        scores[i] = score\n",
      "    return(np.mean(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_ = np.array( [X_dict_by_cid[cid] for cid in Y_cid_dil_rest_avg[:, 0] ] )\n",
      "precno_preverjanje(X_, Y_cid_dil_rest_avg, 10, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "1.7584138867943426"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}