{
 "metadata": {
  "name": "",
  "signature": "sha256:9b5b1359abe6052d6a836dd148faa5f91ffe68c30d1154f9822e2c52a1f52130"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import\n",
      "from collections import defaultdict\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "import pylab as P\n",
      "import Orange\n",
      "from sklearn import decomposition\n",
      "from sklearn import linear_model\n",
      "from sklearn import ensemble\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "import scipy\n",
      "import math\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stringTOfloat(matrix):\n",
      "    \"\"\"Cast string values of a matrix into float values\"\"\"\n",
      "    matrix1 = []\n",
      "    for pos in range(len(matrix)):\n",
      "        i = matrix[pos]\n",
      "        #i[i == ''] = 0.0\n",
      "        i = i.astype(np.float)\n",
      "        matrix1.append(i)\n",
      "    return np.array( matrix1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def NANto0(matrix):\n",
      "    # Daj vse NAN na 0 -> ni ok, ampak za zacetek bo ok\n",
      "    for i in range(len(matrix)):\n",
      "        for j in range(len(matrix[i])):\n",
      "            if np.isnan(matrix[i,j]):\n",
      "                matrix[i,j] = 0\n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(name):\n",
      "    file1 = open(name, \"rU\" )\n",
      "    Y = []\n",
      "    for aRow in file1:\n",
      "        Y.append(aRow.split('\\t'))\n",
      "    file1.close()\n",
      "    return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse dilution and get denominator\n",
      "def get_dilution_denominator( string ):\n",
      "    i = 0\n",
      "    # Get rid of numerator\n",
      "    while ( string[i] != '/' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Get rid of '/'\n",
      "    while ( string[i] != '1' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Count zeros in denominator\n",
      "    n_zeros = 0\n",
      "    for j in range(i, len(string)):\n",
      "        if string[j] == '0':\n",
      "            n_zeros += 1\n",
      "            \n",
      "    return 10**n_zeros "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getX():\n",
      "    X = getData(\"../data/molecular_descriptors_data.txt\")\n",
      "    \n",
      "    # remove header\n",
      "    X = np.array(X[1:])\n",
      "    X = stringTOfloat(X)\n",
      "    # set Nan to 0\n",
      "    X = NANto0(X)\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getY():\n",
      "    Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "    \n",
      "    # header\n",
      "    head = Y[0]\n",
      "    \n",
      "    # remove header\n",
      "    Y = np.array(Y[1:])\n",
      "    \n",
      "    # get CID, get dil\n",
      "    cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "    dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "   \n",
      "    # from \n",
      "    Y_rest = np.array(Y[:, 6:]) \n",
      "    Y_rest = stringTOfloat(Y_rest)\n",
      "    \n",
      "    Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "    Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      " \n",
      "    # average\n",
      "    # get cids\n",
      "    cids_unique = np.unique(np.array(cids)[0])\n",
      "    \n",
      "    # for each cid store avg value for all attributes\n",
      "    cid_avg = []\n",
      "    for cid in cids_unique:\n",
      "        cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "        dil_low = cid_samples[0][1] \n",
      "        dil_high = cid_samples[1][1] \n",
      "        cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil        \n",
      "        # average\n",
      "        avg_low = [np.median(column[~np.isnan(column)]) for column in cid_samples_rest[0::2].T]\n",
      "        avg_high = [np.median(column[~np.isnan(column)]) for column in cid_samples_rest[1::2].T]\n",
      "        # concatenate cid with average values\n",
      "        cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "        cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "        \n",
      "    cid_avg = np.array( cid_avg )\n",
      "    return cid_avg, head\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "\n",
      "# header\n",
      "head = Y[0]\n",
      "\n",
      "# remove header\n",
      "Y = np.array(Y[1:])\n",
      "\n",
      "# get CID, get dil\n",
      "cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "\n",
      "# from \n",
      "Y_rest = np.array(Y[:, 6:]) \n",
      "Y_rest = stringTOfloat(Y_rest)\n",
      "\n",
      "Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      "\n",
      "# average\n",
      "# get cids\n",
      "cids_unique = np.unique(np.array(cids)[0])\n",
      "\n",
      "# for each cid store avg value for all attributes\n",
      "cid_avg = []\n",
      "for cid in cids_unique:\n",
      "    cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "    dil_low = cid_samples[0][1] \n",
      "    dil_high = cid_samples[1][1] \n",
      "    cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil        \n",
      "    # average\n",
      "    break\n",
      "    avg_low = [np.median(np.array(column[~np.isnan(column)])) for column in cid_samples_rest[0::2].T]\n",
      "    avg_high = [np.median(np.array(column[~np.isnan(column)])) for column in cid_samples_rest[1::2].T]\n",
      "    # concatenate cid with average values\n",
      "    cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "    cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "\n",
      "cid_avg = np.array( cid_avg )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPredict():\n",
      "    P = getData(\"../data/predict.txt\")\n",
      "    \n",
      "    P = np.array(P)\n",
      "    \n",
      "    # get CID\n",
      "    cids = stringTOfloat(P[:,0])\n",
      "    dils = [get_dilution_denominator(dil) for dil in P[:,1]]\n",
      "    \n",
      "    P = []\n",
      "    for i in range( len(cids) ):\n",
      "        P.append((cids[i], dils[i]))\n",
      "    return np.array(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pravzaprav, ne uporabljam\n",
      "def normalize_correct(matrix):\n",
      "    size = matrix.shape\n",
      "    for i in range( size[1] ):\n",
      "        sum = 0\n",
      "        n = 0\n",
      "        # Get sum of column\n",
      "        for j in range( size[0] ):\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                pass\n",
      "            else:\n",
      "                sum += abs(matrix[j,i])\n",
      "                n += 1\n",
      "          \n",
      "        # Correct each value in column\n",
      "        for j in range( size[0] ):\n",
      "            # NaN -> avg value\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                matrix[j,i] = sum / n\n",
      "                \n",
      "            # sum = 0 -> 0\n",
      "            elif sum == 0:\n",
      "                matrix[j,i] = 0\n",
      "                \n",
      "            # else value / sum\n",
      "            else:\n",
      "                matrix[j,i] = matrix[j,i] / sum\n",
      "                \n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_by_cid_and_dilution(Y, dilution = None):\n",
      "    \"\"\"Compute average attributes for CID. Dilution influences, which samples to take.\"\"\"\n",
      "    \n",
      "    if dilution != None:\n",
      "        # if dilution not None, take only samples with that dilution\n",
      "        return Y[Y[:,1] == dilution]\n",
      "    else:\n",
      "        # if None, then take all Y\n",
      "        return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_by_cid_and_low_high_dilution(Y, high=True):\n",
      "    \"\"\"Compute average attributes for CID. Based on high or low\"\"\"\n",
      "    # average for each cid and dilution\n",
      "    \n",
      "    if high:\n",
      "        return Y[1::2]  # take high dilutions\n",
      "    else:\n",
      "        return Y[0::2]  # take low dilutions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_X_Y_train(X_dict, Y):    \n",
      "    # connect them together\n",
      "    X_train = []\n",
      "    Y_train = np.array( cid_avg[:, 1:] )\n",
      "    for cid in Y[:, 0]:\n",
      "        X_train.append((X_dict[cid]))\n",
      "    X_train = np.array( X_train )\n",
      "    return X_train, Y_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ne uporabljam\n",
      "def best_model(X_train, Y_train):\n",
      "    best_m = None\n",
      "    best_val = 100\n",
      "    best_alpha = 0\n",
      "    best_ratio = 0\n",
      "    for alpha in [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10]:\n",
      "        for ratio in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
      "            elastic = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio, max_iter=500)\n",
      "            rez = my_cross_validation(X_train, Y_train, elastic)\n",
      "            if rez < best_val:\n",
      "                best_m = elastic\n",
      "                best_val = rez\n",
      "                best_alpha = alpha\n",
      "                best_ratio = ratio\n",
      "    # return best model\n",
      "    return best_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ne uproabljam\n",
      "def my_cross_validation(X, y, model):\n",
      "\n",
      "    k = 10\n",
      "    components = 10\n",
      "    \n",
      "    kf = cross_validation.KFold(len(y), n_folds=5)\n",
      "    rmse = []\n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "\n",
      "        X_sel_tr, X_sel_tst = X_train, X_test\n",
      "        # learn\n",
      "        lrn = model.fit(X_sel_tr, y_train)\n",
      "        # predict\n",
      "        pred = lrn.predict(X_sel_tst)\n",
      "        # rmse\n",
      "        rmse.append(np.sqrt(sum((pred - y_test)**2)/len(y_test)))\n",
      "    return( np.mean(rmse) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file(cid_preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../rezults/'+name+'.txt','w')\n",
      "    for cid, pred in cid_preds:\n",
      "        for i in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[i])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[i]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NORM_STD = [ 0.18, 0.16, 0.06 ] #an average of normalizatin_costs outputs)\n",
      "#means were 0 (as expected for Pearson correlation)\n",
      "\n",
      "def pearson(x,y):\n",
      "    x,y = np.array(x), np.array(y)\n",
      "    anynan = np.logical_or(np.isnan(x), np.isnan(y))\n",
      "    r = scipy.stats.pearsonr(x[~anynan],y[~anynan])[0]\n",
      "    return 0. if math.isnan(r) else r\n",
      "\n",
      "def final_score(rs):\n",
      "    zs = rs/NORM_STD\n",
      "    return np.mean(zs)\n",
      "\n",
      "def evaluate_r(prediction, real):\n",
      "    userscores = prediction\n",
      "    realscores = real\n",
      "    rint = pearson(userscores[:,0], realscores[:,0])\n",
      "    rval = pearson(userscores[:,1], realscores[:,1])\n",
      "    rdecall = [ pearson(userscores[:,i], realscores[:,i]) for i in range(2,21) ]\n",
      "    rdec = np.mean(rdecall)\n",
      "    return np.array([rint, rval, rdec])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pca(X_sel_tr, components):\n",
      "    pca = decomposition.PCA(n_components=components)\n",
      "    pca.fit(X_sel_tr)\n",
      "    X_sel_tr = pca.transform(X_sel_tr)\n",
      "    return X_sel_tr, pca"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def standardize(X_sel_tr):\n",
      "    scaler = preprocessing.StandardScaler()\n",
      "    scaler.fit(X_sel_tr) #shranimo transformacijo\n",
      "    X_sel_tr = scaler.transform(X_sel_tr) #transformiramo X (standardiziramo)\n",
      "    return X_sel_tr, scaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_models(X_sel_tr, Y_train, dilution):\n",
      "    \"\"\"Create scalar, pca and 21 models for a given dilution\"\"\"\n",
      "\n",
      "    model = linear_model.RidgeCV()\n",
      "    #model = linear_model.ElasticNetCV()\n",
      "    #model = ensemble.RandomForestClassifier()\n",
      "    \n",
      "    models_list = []\n",
      "    for i in range(0,(Y_train.shape)[1]):\n",
      "        #print('start learn', i)\n",
      "        # learn\n",
      "        lrn = model.fit(X_sel_tr, Y_train[:, i])\n",
      "        models_list += [lrn]\n",
      "    \n",
      "    return models_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RUN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PO\u017dENI 1\n",
      "# cid, rest\n",
      "X_cid_rest = getX()\n",
      "# cid, dilution, rest\n",
      "Y_cid_dil_rest, head = getY()\n",
      "# predict info\n",
      "toPredict = getPredict()\n",
      "# Create access to chemical informations via CID\n",
      "X_dict_by_cid = dict([(i[0], i[1:]) for i in X_cid_rest])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "kth(=24) out of bounds (1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-67-dceb77da37e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_cid_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# cid, dilution, rest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mY_cid_dil_rest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# predict info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtoPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-48-5597f7609b2c>\u001b[0m in \u001b[0;36mgetY\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mcid_samples_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcid_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# remove cid and dil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mavg_low\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcid_samples_rest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mavg_high\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcid_samples_rest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# concatenate cid with average values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-48-5597f7609b2c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mcid_samples_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcid_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# remove cid and dil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mavg_low\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcid_samples_rest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mavg_high\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcid_samples_rest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# concatenate cid with average values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   2888\u001b[0m     \"\"\"\n\u001b[0;32m   2889\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 2890\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   2891\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   2801\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2803\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2804\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   2927\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msz\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2928\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2929\u001b[1;33m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msz\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2930\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2931\u001b[0m         \u001b[1;31m# make 0-D arrays work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: kth(=24) out of bounds (1)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dils = np.unique(Y_cid_dil_rest[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dils_predict = dict()\n",
      "for dil in unique_dils:\n",
      "    \n",
      "    # Get y for intensity and pleasantness\n",
      "    Y_int_ple = Y_cid_dil_rest[ Y_cid_dil_rest[:,1] == 1000]\n",
      "    # Get for rest\n",
      "    Y_rest = average_by_cid_and_low_high_dilution(Y_cid_dil_rest, high=True)\n",
      "    \n",
      "    \n",
      "    #Y_cid_dil_rest_avg = average_by_cid_and_dilution(Y_cid_dil_rest, dil)\n",
      "    #Y_cid_avg = average_by_cid_and_low_high_dilution(Y_cid_dil_rest, high=True)\n",
      "    \n",
      "    #y_train = Y_cid_dil_rest_avg[:, 2:]  # remove cid and dilution, take rest\n",
      "    \n",
      "    # Pripravi X glede na Y\n",
      "    X_int_ple = np.array( [X_dict_by_cid[cid] for cid in Y_int_ple[:, 0] ] )\n",
      "    X_rest = np.array( [X_dict_by_cid[cid] for cid in Y_rest[:, 0] ] )\n",
      "    \n",
      "    Y_int_ple = Y_int_ple[:, 2:4]  # remove rest\n",
      "    Y_rest = Y_rest[:, 4:]   # remove rest\n",
      "\n",
      "    # Standardize\n",
      "    #X_int_ple, scalar_int_ple = standardize(X_int_ple)\n",
      "    #X_rest, scalar_rest = standardize(X_rest)\n",
      "    \n",
      "    # Pca\n",
      "    #X_int_ple, pca_int_ple = get_pca(X_int_ple, 20)\n",
      "    #X_rest, pca_rest = get_pca(X_rest, 20)\n",
      "    \n",
      "    # Get models\n",
      "    models_list_int_ple = compute_models(X_int_ple, Y_int_ple, dil)\n",
      "    models_list_rest = compute_models(X_rest, Y_rest, dil)\n",
      "    \n",
      "    models_list = models_list_int_ple + models_list_rest\n",
      "    \n",
      "    dils_predict[int(dil)] = (pca_int_ple, pca_rest, models_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CROSS VALIDATION, izpise vmesni prediction, na koncu pa SCORE\n",
      "# Pripravi Y v odvisnosti od vhoda cid in dilutiona\n",
      "\n",
      "# Razbijemo glavno mnozico, ucno mnozico\n",
      "\n",
      "repetitions = 3\n",
      "S = 0\n",
      "kf = cross_validation.KFold(len(Y_cid_dil_rest), n_folds=repetitions)\n",
      "store_predictions = []\n",
      "for train_index, test_index in kf:\n",
      "    #X_train, X_test = X[train_index], X[test_index]\n",
      "    # divide for CV\n",
      "    Y_cid_dil_rest_train, Y_cid_dil_rest_test = Y_cid_dil_rest[train_index], Y_cid_dil_rest[test_index]\n",
      "    \n",
      "    # prepare examples to predict\n",
      "    toPredict = [(Y_cid_dil_rest_test[i, 0], Y_cid_dil_rest_test[i, 1]) for i in range((Y_cid_dil_rest_test.shape)[0])]\n",
      "    \n",
      "    for pr in toPredict:\n",
      "        cid = pr[0]\n",
      "        dil = pr[1]\n",
      "\n",
      "        X_to_predict = X_dict_by_cid[cid]        \n",
      "        pca_int_ple, pca_rest, models_list = dils_predict[int(dil)]\n",
      "        \n",
      "        #X_to_predict = scalar.transform(X_to_predict)\n",
      "        X_to_predict_int_ple = pca_int_ple.transform(X_to_predict)\n",
      "        X_to_predict_rest = pca_rest.transform(X_to_predict)\n",
      "        \n",
      "        rezult = []\n",
      "        for i in range(len(models_list)):\n",
      "            model = models_list[i]\n",
      "            if i < 2:\n",
      "                X_to_predict = X_to_predict_int_ple\n",
      "            else:\n",
      "                X_to_predict = X_to_predict_rest\n",
      "                \n",
      "            p = model.predict(X_to_predict)\n",
      "            rezult += [p[0]]\n",
      "        store_predictions += [np.array(rezult)]\n",
      "    \n",
      "    store_predictions = np.array(store_predictions)\n",
      "\n",
      "    # evaluate\n",
      "    score = evaluate_r(store_predictions, Y_cid_dil_rest_test)\n",
      "    score = final_score(score)\n",
      "    print(\"Vmesni .................\", score)\n",
      "    S += score\n",
      "    \n",
      "print(\"FINAL .................\", S/repetitions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vmesni ................. 0.203726354563\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.256422239942\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.708314782735\n",
        "FINAL ................. -0.253670222705\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.31877779176"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "1.31877779176"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_to_file(cid_preds, head, 'forest_2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "elasticCV = 1.06\n",
      "ridge = 2.04792 "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}