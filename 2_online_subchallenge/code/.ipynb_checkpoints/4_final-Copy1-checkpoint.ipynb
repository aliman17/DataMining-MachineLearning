{
 "metadata": {
  "name": "",
  "signature": "sha256:23b7b07eab8a5377b8627b61b1c657ff993da46dfcf86af36f93d4d9b9e4c37d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import\n",
      "from collections import defaultdict\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "import pylab as P\n",
      "import Orange\n",
      "from sklearn import decomposition\n",
      "from sklearn import linear_model\n",
      "from sklearn import ensemble\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "import scipy\n",
      "import math\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stringTOfloat(matrix):\n",
      "    \"\"\"Cast string values of a matrix into float values\"\"\"\n",
      "    matrix1 = []\n",
      "    for pos in range(len(matrix)):\n",
      "        i = matrix[pos]\n",
      "        #i[i == ''] = 0.0\n",
      "        i = i.astype(np.float)\n",
      "        matrix1.append(i)\n",
      "    return np.array( matrix1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def NANto0(matrix):\n",
      "    # Daj vse NAN na 0 -> ni ok, ampak za zacetek bo ok\n",
      "    for i in range(len(matrix)):\n",
      "        for j in range(len(matrix[i])):\n",
      "            if np.isnan(matrix[i,j]):\n",
      "                matrix[i,j] = 0\n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(name):\n",
      "    file1 = open(name, \"rU\" )\n",
      "    Y = []\n",
      "    for aRow in file1:\n",
      "        Y.append(aRow.split('\\t'))\n",
      "    file1.close()\n",
      "    return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse dilution and get denominator\n",
      "def get_dilution_denominator( string ):\n",
      "    i = 0\n",
      "    # Get rid of numerator\n",
      "    while ( string[i] != '/' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Get rid of '/'\n",
      "    while ( string[i] != '1' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Count zeros in denominator\n",
      "    n_zeros = 0\n",
      "    for j in range(i, len(string)):\n",
      "        if string[j] == '0':\n",
      "            n_zeros += 1\n",
      "            \n",
      "    return 10**n_zeros "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getX():\n",
      "    X = getData(\"../data/molecular_descriptors_data.txt\")\n",
      "    \n",
      "    # remove header\n",
      "    X = np.array(X[1:])\n",
      "    X = stringTOfloat(X)\n",
      "    # set Nan to 0\n",
      "    X = NANto0(X)\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getY():\n",
      "    Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "    \n",
      "    # header\n",
      "    head = Y[0]\n",
      "    \n",
      "    # remove header\n",
      "    Y = np.array(Y[1:])\n",
      "    \n",
      "    # get CID, get dil\n",
      "    cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "    dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "   \n",
      "    # from \n",
      "    Y_rest = np.array(Y[:, 6:]) \n",
      "    Y_rest = stringTOfloat(Y_rest)\n",
      "    \n",
      "    Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "    Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      " \n",
      "    \n",
      "    return Y_cid_dil_rest, head\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avg_median(Y_cid_dil_rest):\n",
      "    \n",
      "    cids = Y_cid_dil_rest[:, 0]\n",
      "    dils = Y_cid_dil_rest[:, 1]\n",
      "    # average\n",
      "    # get cids\n",
      "    cids_unique = np.unique(np.array(cids))\n",
      "    \n",
      "    # for each cid store avg value for all attributes\n",
      "    cid_avg = []\n",
      "    for cid in cids_unique:\n",
      "        cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "        dil_low = cid_samples[0][1] \n",
      "        dil_high = cid_samples[1][1] \n",
      "        cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil        \n",
      "        # average\n",
      "        avg_low = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest[0::2].T]\n",
      "        avg_high = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest[1::2].T]\n",
      "        # concatenate cid with average values\n",
      "        cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "        cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "        \n",
      "    cid_avg = np.array( cid_avg )\n",
      "    return cid_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_median(Y_cid_dil_rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "array([[  1.26000000e+02,   1.00000000e+03,   2.46530612e+01, ...,\n",
        "          1.79411765e+00,   5.08823529e+00,   1.45294118e+01],\n",
        "       [  1.26000000e+02,   1.00000000e+01,   4.95510204e+01, ...,\n",
        "          1.34782609e+00,   9.26086957e+00,   1.42391304e+01],\n",
        "       [  1.76000000e+02,   1.00000000e+05,   1.15510204e+01, ...,\n",
        "          1.96153846e+00,   4.11538462e+00,   3.38461538e+00],\n",
        "       ..., \n",
        "       [  6.42933300e+06,   1.00000000e+05,   1.28571429e+01, ...,\n",
        "          4.96774194e+00,   8.61290323e+00,   1.14838710e+01],\n",
        "       [  6.99997700e+06,   1.00000000e+05,   1.78367347e+01, ...,\n",
        "          3.00000000e+00,   6.19047619e+00,   1.27619048e+01],\n",
        "       [  6.99997700e+06,   1.00000000e+03,   4.51428571e+01, ...,\n",
        "          2.07142857e+00,   2.73809524e+00,   1.01190476e+01]])"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "\n",
      "# header\n",
      "head = Y[0]\n",
      "\n",
      "# remove header\n",
      "Y = np.array(Y[1:])\n",
      "\n",
      "# get CID, get dil\n",
      "cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "\n",
      "# from \n",
      "Y_rest = np.array(Y[:, 6:]) \n",
      "Y_rest = stringTOfloat(Y_rest)\n",
      "\n",
      "Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      "\n",
      "# average\n",
      "# get cids\n",
      "cids_unique = np.unique(np.array(cids)[0])\n",
      "\n",
      "# for each cid store avg value for all attributes\n",
      "cid_avg = []\n",
      "for cid in cids_unique:\n",
      "    cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "    dil_low = cid_samples[0][1] \n",
      "    dil_high = cid_samples[1][1] \n",
      "    cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil        \n",
      "    # average\n",
      "    break\n",
      "    avg_low = [np.median(np.array(column[~np.isnan(column)])) for column in cid_samples_rest[0::2].T]\n",
      "    avg_high = [np.median(np.array(column[~np.isnan(column)])) for column in cid_samples_rest[1::2].T]\n",
      "    # concatenate cid with average values\n",
      "    cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "    cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "\n",
      "cid_avg = np.array( cid_avg )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPredict():\n",
      "    P = getData(\"../data/predict.txt\")\n",
      "    \n",
      "    P = np.array(P)\n",
      "    \n",
      "    # get CID\n",
      "    cids = stringTOfloat(P[:,0])\n",
      "    dils = [get_dilution_denominator(dil) for dil in P[:,1]]\n",
      "    \n",
      "    P = []\n",
      "    for i in range( len(cids) ):\n",
      "        P.append((cids[i], dils[i]))\n",
      "    return np.array(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pravzaprav, ne uporabljam\n",
      "def normalize_correct(matrix):\n",
      "    size = matrix.shape\n",
      "    for i in range( size[1] ):\n",
      "        sum = 0\n",
      "        n = 0\n",
      "        # Get sum of column\n",
      "        for j in range( size[0] ):\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                pass\n",
      "            else:\n",
      "                sum += abs(matrix[j,i])\n",
      "                n += 1\n",
      "          \n",
      "        # Correct each value in column\n",
      "        for j in range( size[0] ):\n",
      "            # NaN -> avg value\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                matrix[j,i] = sum / n\n",
      "                \n",
      "            # sum = 0 -> 0\n",
      "            elif sum == 0:\n",
      "                matrix[j,i] = 0\n",
      "                \n",
      "            # else value / sum\n",
      "            else:\n",
      "                matrix[j,i] = matrix[j,i] / sum\n",
      "                \n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_by_cid_and_dilution(Y, dilution = None):\n",
      "    \"\"\"Compute average attributes for CID. Dilution influences, which samples to take.\"\"\"\n",
      "    \n",
      "    if dilution != None:\n",
      "        # if dilution not None, take only samples with that dilution\n",
      "        return Y[Y[:,1] == dilution]\n",
      "    else:\n",
      "        # if None, then take all Y\n",
      "        return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_by_cid_and_low_high_dilution(Y, high=True):\n",
      "    \"\"\"Compute average attributes for CID. Based on high or low\"\"\"\n",
      "    # average for each cid and dilution\n",
      "    \n",
      "    if high:\n",
      "        return Y[1::2]  # take high dilutions\n",
      "    else:\n",
      "        return Y[0::2]  # take low dilutions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_X_Y_train(X_dict, Y):    \n",
      "    # connect them together\n",
      "    X_train = []\n",
      "    Y_train = np.array( cid_avg[:, 1:] )\n",
      "    for cid in Y[:, 0]:\n",
      "        X_train.append((X_dict[cid]))\n",
      "    X_train = np.array( X_train )\n",
      "    return X_train, Y_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ne uporabljam\n",
      "def best_model(X_train, Y_train):\n",
      "    best_m = None\n",
      "    best_val = 100\n",
      "    best_alpha = 0\n",
      "    best_ratio = 0\n",
      "    for alpha in [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10]:\n",
      "        for ratio in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
      "            elastic = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio, max_iter=500)\n",
      "            rez = my_cross_validation(X_train, Y_train, elastic)\n",
      "            if rez < best_val:\n",
      "                best_m = elastic\n",
      "                best_val = rez\n",
      "                best_alpha = alpha\n",
      "                best_ratio = ratio\n",
      "    # return best model\n",
      "    return best_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ne uproabljam\n",
      "def my_cross_validation(X, y, model):\n",
      "\n",
      "    k = 10\n",
      "    components = 10\n",
      "    \n",
      "    kf = cross_validation.KFold(len(y), n_folds=5)\n",
      "    rmse = []\n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "\n",
      "        X_sel_tr, X_sel_tst = X_train, X_test\n",
      "        # learn\n",
      "        lrn = model.fit(X_sel_tr, y_train)\n",
      "        # predict\n",
      "        pred = lrn.predict(X_sel_tst)\n",
      "        # rmse\n",
      "        rmse.append(np.sqrt(sum((pred - y_test)**2)/len(y_test)))\n",
      "    return( np.mean(rmse) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file(cid_preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../rezults/'+name+'.txt','w')\n",
      "    for cid, pred in cid_preds:\n",
      "        for i in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[i])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[i]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NORM_STD = [ 0.18, 0.16, 0.06 ] #an average of normalizatin_costs outputs)\n",
      "#means were 0 (as expected for Pearson correlation)\n",
      "\n",
      "def pearson(x,y):\n",
      "    x,y = np.array(x), np.array(y)\n",
      "    anynan = np.logical_or(np.isnan(x), np.isnan(y))\n",
      "    r = scipy.stats.pearsonr(x[~anynan],y[~anynan])[0]\n",
      "    return 0. if math.isnan(r) else r\n",
      "\n",
      "def final_score(rs):\n",
      "    zs = rs/NORM_STD\n",
      "    return np.mean(zs)\n",
      "\n",
      "def evaluate_r(prediction, real):\n",
      "    userscores = prediction\n",
      "    realscores = real\n",
      "    rint = pearson(userscores[:,0], realscores[:,0])\n",
      "    rval = pearson(userscores[:,1], realscores[:,1])\n",
      "    rdecall = [ pearson(userscores[:,i], realscores[:,i]) for i in range(2,21) ]\n",
      "    rdec = np.mean(rdecall)\n",
      "    return np.array([rint, rval, rdec])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pca(X_sel_tr, components):\n",
      "    pca = decomposition.PCA(n_components=components)\n",
      "    pca.fit(X_sel_tr)\n",
      "    X_sel_tr = pca.transform(X_sel_tr)\n",
      "    return X_sel_tr, pca"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def standardize(X_sel_tr):\n",
      "    scaler = preprocessing.StandardScaler()\n",
      "    scaler.fit(X_sel_tr) #shranimo transformacijo\n",
      "    X_sel_tr = scaler.transform(X_sel_tr) #transformiramo X (standardiziramo)\n",
      "    return X_sel_tr, scaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_models(X_sel_tr, Y_train, dilution):\n",
      "    \"\"\"Create scalar, pca and 21 models for a given dilution\"\"\"\n",
      "\n",
      "    model = linear_model.RidgeCV()\n",
      "    #model = linear_model.ElasticNetCV()\n",
      "    #model = ensemble.RandomForestClassifier()\n",
      "    \n",
      "    models_list = []\n",
      "    for i in range(0,(Y_train.shape)[1]):\n",
      "        #print('start learn', i)\n",
      "        # learn\n",
      "        lrn = model.fit(X_sel_tr, Y_train[:, i])\n",
      "        models_list += [lrn]\n",
      "    \n",
      "    return models_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RUN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PO\u017dENI 1\n",
      "# cid, rest\n",
      "X_cid_rest = getX()\n",
      "# cid, dilution, rest\n",
      "Y_cid_dil_rest, head = getY()\n",
      "# predict info\n",
      "toPredict = getPredict()\n",
      "# Create access to chemical informations via CID\n",
      "X_dict_by_cid = dict([(i[0], i[1:]) for i in X_cid_rest])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_cid_dil_rest_avg = avg_median(Y_cid_dil_rest)\n",
      "unique_dils = np.unique(Y_cid_dil_rest[:, 1])\n",
      "Y_cid_dil_rest.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "(27244, 23)"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = Y_cid_dil_rest_avg\n",
      "\n",
      "dils_predict = dict()\n",
      "for dil in unique_dils:\n",
      "    \n",
      "    # Get y for intensity and pleasantness\n",
      "    Y_int_ple = Y[ Y[:,1] == 1000]\n",
      "    # Get for rest\n",
      "    Y_rest = average_by_cid_and_low_high_dilution(Y, high=True)\n",
      "    \n",
      "    \n",
      "    #Y_cid_dil_rest_avg = average_by_cid_and_dilution(Y_cid_dil_rest, dil)\n",
      "    #Y_cid_avg = average_by_cid_and_low_high_dilution(Y_cid_dil_rest, high=True)\n",
      "    \n",
      "    #y_train = Y_cid_dil_rest_avg[:, 2:]  # remove cid and dilution, take rest\n",
      "    \n",
      "    # Pripravi X glede na Y\n",
      "    X_int_ple = np.array( [X_dict_by_cid[cid] for cid in Y_int_ple[:, 0] ] )\n",
      "    X_rest = np.array( [X_dict_by_cid[cid] for cid in Y_rest[:, 0] ] )\n",
      "    \n",
      "    Y_int_ple = Y_int_ple[:, 2:4]  # remove rest\n",
      "    Y_rest = Y_rest[:, 4:]   # remove rest\n",
      "\n",
      "    # Standardize\n",
      "    #X_int_ple, scalar_int_ple = standardize(X_int_ple)\n",
      "    #X_rest, scalar_rest = standardize(X_rest)\n",
      "    \n",
      "    # Pca\n",
      "    X_int_ple, pca_int_ple = get_pca(X_int_ple, 20)\n",
      "    X_rest, pca_rest = get_pca(X_rest, 20)\n",
      "    \n",
      "    # Get models\n",
      "    models_list_int_ple = compute_models(X_int_ple, Y_int_ple, dil)\n",
      "    models_list_rest = compute_models(X_rest, Y_rest, dil)\n",
      "    \n",
      "    models_list = models_list_int_ple + models_list_rest\n",
      "    \n",
      "    dils_predict[int(dil)] = (pca_int_ple, pca_rest, models_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "(2, 23)"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CROSS VALIDATION, izpise vmesni prediction, na koncu pa SCORE\n",
      "# Pripravi Y v odvisnosti od vhoda cid in dilutiona\n",
      "\n",
      "# Razbijemo glavno mnozico, ucno mnozico\n",
      "\n",
      "repetitions = 3\n",
      "S = 0\n",
      "kf = cross_validation.KFold(len(Y), n_folds=repetitions)\n",
      "store_predictions = []\n",
      "for train_index, test_index in kf:\n",
      "    #X_train, X_test = X[train_index], X[test_index]\n",
      "    # divide for CV\n",
      "    Y_cid_dil_rest_train, Y_cid_dil_rest_test = Y[train_index], Y[test_index]\n",
      "    \n",
      "    # prepare examples to predict\n",
      "    toPredict = [(Y_cid_dil_rest_test[i, 0], Y_cid_dil_rest_test[i, 1]) for i in range((Y_cid_dil_rest_test.shape)[0])]\n",
      "    \n",
      "    for pr in toPredict:\n",
      "        cid = pr[0]\n",
      "        dil = pr[1]\n",
      "\n",
      "        X_to_predict = X_dict_by_cid[cid]        \n",
      "        pca_int_ple, pca_rest, models_list = dils_predict[int(dil)]\n",
      "        \n",
      "        #X_to_predict = scalar.transform(X_to_predict)\n",
      "        X_to_predict_int_ple = pca_int_ple.transform(X_to_predict)\n",
      "        X_to_predict_rest = pca_rest.transform(X_to_predict)\n",
      "        \n",
      "        rezult = []\n",
      "        for i in range(len(models_list)):\n",
      "            model = models_list[i]\n",
      "            if i < 2:\n",
      "                X_to_predict = X_to_predict_int_ple\n",
      "            else:\n",
      "                X_to_predict = X_to_predict_rest\n",
      "                \n",
      "            p = model.predict(X_to_predict)\n",
      "            rezult += [p[0]]\n",
      "        store_predictions += [np.array(rezult)]\n",
      "    \n",
      "    store_predictions = np.array(store_predictions)\n",
      "\n",
      "    # evaluate\n",
      "    score = evaluate_r(store_predictions, Y_cid_dil_rest_test)\n",
      "    score = final_score(score)\n",
      "    print(\"Vmesni .................\", score)\n",
      "    S += score\n",
      "    \n",
      "print(\"FINAL .................\", S/repetitions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Cannot have number of folds n_folds=3 greater than the number of samples: 2.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-84-b73fe10c38ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrepetitions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mstore_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, n_folds, indices, shuffle, random_state)\u001b[0m\n\u001b[0;32m    316\u001b[0m     def __init__(self, n, n_folds=3, indices=None, shuffle=False,\n\u001b[0;32m    317\u001b[0m                  random_state=None):\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, n_folds, indices, shuffle, random_state)\u001b[0m\n\u001b[0;32m    251\u001b[0m             raise ValueError(\n\u001b[0;32m    252\u001b[0m                 (\"Cannot have number of folds n_folds={0} greater\"\n\u001b[1;32m--> 253\u001b[1;33m                  \" than the number of samples: {1}.\").format(n_folds, n))\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Cannot have number of folds n_folds=3 greater than the number of samples: 2."
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.31877779176"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "1.31877779176"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_to_file(cid_preds, head, 'forest_2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "elasticCV = 1.06\n",
      "ridge = 2.04792 "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}