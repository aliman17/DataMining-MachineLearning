{
 "metadata": {
  "name": "",
  "signature": "sha256:7930b537ef3bc1a80e11b1094332160be6236d7e88f3ed1927424318f375f50a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import\n",
      "from collections import defaultdict\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "import pylab as P\n",
      "import Orange\n",
      "\n",
      "from sklearn import decomposition\n",
      "from sklearn import linear_model\n",
      "from sklearn import ensemble\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "import scipy\n",
      "import math\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stringTOfloat(matrix):\n",
      "    \"\"\"Cast string values of a matrix into float values\"\"\"\n",
      "    matrix1 = []\n",
      "    for pos in range(len(matrix)):\n",
      "        i = matrix[pos]\n",
      "        #i[i == ''] = 0.0\n",
      "        i = i.astype(np.float)\n",
      "        matrix1.append(i)\n",
      "    return np.array( matrix1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def NANto0(matrix):\n",
      "    # Daj vse NAN na 0 -> ni ok, ampak za zacetek bo ok\n",
      "    for i in range(len(matrix)):\n",
      "        for j in range(len(matrix[i])):\n",
      "            if np.isnan(matrix[i,j]):\n",
      "                matrix[i,j] = 0\n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(name):\n",
      "    file1 = open(name, \"rU\" )\n",
      "    Y = []\n",
      "    for aRow in file1:\n",
      "        Y.append(aRow.split('\\t'))\n",
      "    file1.close()\n",
      "    return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse dilution and get denominator\n",
      "def get_dilution_denominator( string ):\n",
      "    i = 0\n",
      "    # Get rid of numerator\n",
      "    while ( string[i] != '/' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Get rid of '/'\n",
      "    while ( string[i] != '1' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Count zeros in denominator\n",
      "    n_zeros = 0\n",
      "    for j in range(i, len(string)):\n",
      "        if string[j] == '0':\n",
      "            n_zeros += 1\n",
      "            \n",
      "    return 10**n_zeros "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getX():\n",
      "    X = getData(\"../data/molecular_descriptors_data.txt\")\n",
      "    \n",
      "    # remove header\n",
      "    X = np.array(X[1:])\n",
      "    X = stringTOfloat(X)\n",
      "    # set Nan to 0\n",
      "    X = NANto0(X)\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getY():\n",
      "    Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "    \n",
      "    # header\n",
      "    head = Y[0]\n",
      "    \n",
      "    # remove header\n",
      "    Y = np.array(Y[1:])\n",
      "    \n",
      "    # get CID, get dil\n",
      "    cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "    dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "   \n",
      "    # from \n",
      "    Y_rest = np.array(Y[:, 6:]) \n",
      "    Y_rest = stringTOfloat(Y_rest)\n",
      "    \n",
      "    Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "    Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      " \n",
      "    \n",
      "    return Y_cid_dil_rest, head\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avg_median(Y_cid_dil_rest):\n",
      "    \n",
      "    cids = Y_cid_dil_rest[:, 0]\n",
      "    dils = Y_cid_dil_rest[:, 1]\n",
      "    # average\n",
      "    # get cids\n",
      "    cids_unique = np.unique(np.array(cids))\n",
      "    \n",
      "    # for each cid store avg value for all attributes\n",
      "    cid_avg = []\n",
      "    for cid in cids_unique:\n",
      "        cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "        dil_low = cid_samples[0][1] \n",
      "        dil_high = cid_samples[1][1] \n",
      "        cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil  \n",
      "        cid_samples_rest = np.array(cid_samples_rest[0::2].T)\n",
      "        # average\n",
      "        avg_low = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest]\n",
      "        avg_high = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest]\n",
      "        # concatenate cid with average values\n",
      "        cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "        cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "        \n",
      "    cid_avg = np.array( cid_avg )\n",
      "    return cid_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPredict():\n",
      "    P = getData(\"../data/predict.txt\")\n",
      "    \n",
      "    P = np.array(P)\n",
      "    \n",
      "    # get CID\n",
      "    cids = stringTOfloat(P[:,0])\n",
      "    dils = [get_dilution_denominator(dil) for dil in P[:,1]]\n",
      "    \n",
      "    P = []\n",
      "    for i in range( len(cids) ):\n",
      "        P.append((cids[i], dils[i]))\n",
      "    return np.array(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pravzaprav, ne uporabljam\n",
      "def normalize_correct(matrix):\n",
      "    size = matrix.shape\n",
      "    for i in range( size[1] ):\n",
      "        sum = 0\n",
      "        n = 0\n",
      "        # Get sum of column\n",
      "        for j in range( size[0] ):\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                pass\n",
      "            else:\n",
      "                sum += abs(matrix[j,i])\n",
      "                n += 1\n",
      "          \n",
      "        # Correct each value in column\n",
      "        for j in range( size[0] ):\n",
      "            # NaN -> avg value\n",
      "            if np.isnan(matrix[j,i]):\n",
      "                matrix[j,i] = sum / n\n",
      "                \n",
      "            # sum = 0 -> 0\n",
      "            elif sum == 0:\n",
      "                matrix[j,i] = 0\n",
      "                \n",
      "            # else value / sum\n",
      "            else:\n",
      "                matrix[j,i] = matrix[j,i] / sum\n",
      "                \n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select_dilution(Y, dilution = None):\n",
      "    \"\"\"Compute average attributes for CID. Dilution influences, which samples to take.\"\"\"\n",
      "    \n",
      "    if dilution != None:\n",
      "        # if dilution not None, take only samples with that dilution\n",
      "        return Y[Y[:,1] == dilution]\n",
      "    else:\n",
      "        # if None, then take all Y\n",
      "        return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select_low_high_dilution(Y, high=True):\n",
      "    \"\"\"Compute average attributes for CID. Based on high or low\"\"\"\n",
      "    # average for each cid and dilution\n",
      "    \n",
      "    if high:\n",
      "        return Y[1::2]  # take high dilutions\n",
      "    else:\n",
      "        return Y[0::2]  # take low dilutions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ne uporabljam\n",
      "def best_model(X_train, Y_train):\n",
      "    best_m = None\n",
      "    best_val = 100\n",
      "    best_alpha = 0\n",
      "    best_ratio = 0\n",
      "    for alpha in [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10]:\n",
      "        for ratio in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
      "            elastic = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio, max_iter=500)\n",
      "            rez = my_cross_validation(X_train, Y_train, elastic)\n",
      "            if rez < best_val:\n",
      "                best_m = elastic\n",
      "                best_val = rez\n",
      "                best_alpha = alpha\n",
      "                best_ratio = ratio\n",
      "    # return best model\n",
      "    return best_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file(cid_preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../rezults/'+name+'.txt','w')\n",
      "    for cid, pred in cid_preds:\n",
      "        for i in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[i])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[i]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()\n",
      "    \n",
      "def write_to_file2(cids, preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../rezults/'+name+'.txt','w')\n",
      "    for i in range(len(cids)):\n",
      "        cid = cids[i]\n",
      "        pred = preds[i]\n",
      "        for j in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[j])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[j]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NORM_STD = [ 0.18, 0.16, 0.06 ] #an average of normalizatin_costs outputs)\n",
      "#means were 0 (as expected for Pearson correlation)\n",
      "\n",
      "def pearson(x,y):\n",
      "    x,y = np.array(x), np.array(y)\n",
      "    anynan = np.logical_or(np.isnan(x), np.isnan(y))\n",
      "    r = scipy.stats.pearsonr(x[~anynan],y[~anynan])[0]\n",
      "    return 0. if math.isnan(r) else r\n",
      "\n",
      "def final_score(rs):\n",
      "    zs = rs/NORM_STD\n",
      "    return np.mean(zs)\n",
      "\n",
      "def evaluate_r(prediction, real):\n",
      "    userscores = prediction\n",
      "    realscores = real\n",
      "    rint = pearson(userscores[:,0], realscores[:,0])\n",
      "    rval = pearson(userscores[:,1], realscores[:,1])\n",
      "    rdecall = [ pearson(userscores[:,i], realscores[:,i]) for i in range(2,21) ]\n",
      "    rdec = np.mean(rdecall)\n",
      "    return np.array([rint, rval, rdec])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pca(X_sel_tr, components):\n",
      "    pca = decomposition.PCA(n_components=components)\n",
      "    pca.fit(X_sel_tr)\n",
      "    X_sel_tr = pca.transform(X_sel_tr)\n",
      "    return X_sel_tr, pca"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def standardize(X_sel_tr):\n",
      "    scaler = preprocessing.StandardScaler()\n",
      "    scaler.fit(X_sel_tr) #shranimo transformacijo\n",
      "    X_sel_tr = scaler.transform(X_sel_tr) #transformiramo X (standardiziramo)\n",
      "    return X_sel_tr, scaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_models(X_sel_tr, Y_train, dilution):\n",
      "    \"\"\"Create scalar, pca and 21 models for a given dilution\"\"\"\n",
      "\n",
      "    #model = linear_model.RidgeCV()\n",
      "    #model = linear_model.ElasticNetCV()\n",
      "    #model = linear_model.ElasticNet()\n",
      "    #model = ensemble.RandomForestRegressor(n_estimators=50, max_depth=None, min_samples_split=5, random_state=0, n_jobs=1)\n",
      "    model = ensemble.GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')    \n",
      "\n",
      "    models_list = []\n",
      "    for i in range(0,(Y_train.shape)[1]):\n",
      "        #print('start learn', i)\n",
      "        # learn\n",
      "        lrn = model.fit(X_sel_tr, Y_train[:, i])\n",
      "        models_list += [lrn]\n",
      "    \n",
      "    return models_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def learn_models(X_dict_by_cid, Y, unique_dils):\n",
      "    dils_models = dict()\n",
      "    for dil in unique_dils:\n",
      "\n",
      "        # Get y for intensity and pleasantness\n",
      "        Y_int_ple = Y[ Y[:,1] == 1000]\n",
      "        # Get for rest\n",
      "        Y_rest = select_low_high_dilution(Y, high=True)\n",
      "\n",
      "\n",
      "        #Y_cid_dil_rest_avg = select_dilution(Y, dil)\n",
      "        #Y_cid_avg = select_low_high_dilution(Y_cid_dil_rest, high=True)\n",
      "\n",
      "        #y_train = Y_cid_dil_rest_avg[:, 2:]  # remove cid and dilution, take rest\n",
      "\n",
      "        # Pripravi X glede na Y\n",
      "        X_int_ple = np.array( [X_dict_by_cid[cid] for cid in Y_int_ple[:, 0] ] )\n",
      "        X_rest = np.array( [X_dict_by_cid[cid] for cid in Y_rest[:, 0] ] )\n",
      "\n",
      "        Y_int_ple = Y_int_ple[:, 2:4]  # remove rest\n",
      "        Y_rest = Y_rest[:, 4:]   # remove rest\n",
      "\n",
      "        # Standardize\n",
      "        scalar_int_ple = None\n",
      "        scalar_rest = None\n",
      "        #X_int_ple, scalar_int_ple = standardize(X_int_ple)\n",
      "        #X_rest, scalar_rest = standardize(X_rest)\n",
      "\n",
      "        # Pca\n",
      "        X_int_ple, pca_int_ple = get_pca(X_int_ple, 20)\n",
      "        X_rest, pca_rest = get_pca(X_rest, 20)\n",
      "\n",
      "        # Get models\n",
      "        models_list_int_ple = compute_models(X_int_ple, Y_int_ple, dil)\n",
      "        models_list_rest = compute_models(X_rest, Y_rest, dil)\n",
      "\n",
      "        models_list = models_list_int_ple + models_list_rest\n",
      "\n",
      "        dils_models[int(dil)] = (scalar_int_ple, scalar_rest, pca_int_ple, pca_rest, models_list)\n",
      "        \n",
      "    return dils_models"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adjusted fast cross validation\n",
      "def CV_fast(X_dict_by_cid, Y_cid_dil_rest, dils_models):\n",
      "    repetitions = 3\n",
      "    S = 0\n",
      "    kf = cross_validation.KFold(len(Y_cid_dil_rest), n_folds=repetitions)\n",
      "   \n",
      "    for train_index, test_index in kf:\n",
      "        #X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_cid_dil_rest_train, Y_cid_dil_rest_test = Y_cid_dil_rest[train_index], Y_cid_dil_rest[test_index]\n",
      "\n",
      "        # prepare examples to predict\n",
      "        toPredict = [(Y_cid_dil_rest_test[i, 0], Y_cid_dil_rest_test[i, 1]) for i in range((Y_cid_dil_rest_test.shape)[0])]\n",
      "        store_predictions = []\n",
      "        for pr in toPredict:\n",
      "            cid = pr[0]\n",
      "            dil = pr[1]\n",
      "\n",
      "            X_to_predict = X_dict_by_cid[cid]        \n",
      "            scalar_int_ple, scalar_rest, pca_int_ple, pca_rest, models_list = dils_models[int(dil)]\n",
      "\n",
      "            # Standardize\n",
      "            if not scalar_int_ple == None:\n",
      "                X_to_predict_int_ple = scalar_int_ple.transform(X_to_predict)\n",
      "                X_to_predict_rest = scalar_rest.transform(X_to_predict)\n",
      "            \n",
      "            # Pca\n",
      "            X_to_predict_int_ple = pca_int_ple.transform(X_to_predict)\n",
      "            X_to_predict_rest = pca_rest.transform(X_to_predict)\n",
      "\n",
      "            rezult = []\n",
      "            for i in range(len(models_list)):\n",
      "                model = models_list[i]\n",
      "                if i < 2:\n",
      "                    X_to_predict = X_to_predict_int_ple\n",
      "                else:\n",
      "                    X_to_predict = X_to_predict_rest\n",
      "\n",
      "                p = model.predict(X_to_predict)\n",
      "                rezult += [p[0]]\n",
      "            store_predictions += [np.array(rezult)]\n",
      "        store_predictions = np.array(store_predictions)\n",
      "        \n",
      "        # evaluate\n",
      "        score = evaluate_r(store_predictions, Y_cid_dil_rest_test)\n",
      "        score = final_score(score)\n",
      "        print(\"Vmesni .................\", score)\n",
      "        S += score\n",
      "\n",
      "    print(\"FINAL .................\", S/repetitions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# General cross validation\n",
      "def CV(X, Y, model):\n",
      "    repetitions = 5\n",
      "    S = 0\n",
      "    kf = cross_validation.KFold(len(Y), n_folds=repetitions)\n",
      "   \n",
      "    for train_index, test_index in kf:\n",
      "        print('Start new fold')\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
      "        \n",
      "        X_train, std = standardize(X_train)\n",
      "        X_test = std.transform(X_test)\n",
      "        \n",
      "        X_train, pca = get_pca(X_train, 20)\n",
      "        X_test = pca.transform(X_test)\n",
      "        \n",
      "        store_predictions = []\n",
      "        for i in range((Y_train.shape)[1]):\n",
      "            model.fit(X_train, Y_train[:, i])\n",
      "            P = model.predict(X_test)\n",
      "            store_predictions.append(P)\n",
      "\n",
      "        store_predictions = np.array(store_predictions)\n",
      "        store_predictions = np.matrix(store_predictions).T\n",
      "        store_predictions = np.array(store_predictions)\n",
      "        # evaluate\n",
      "        score = evaluate_r(store_predictions, Y_test)\n",
      "        score = final_score(score)\n",
      "        print(\"Vmesni .................\", score)\n",
      "        S += score\n",
      "\n",
      "    print(\"FINAL .................\", S/repetitions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prediction(X_train, Y_train, X_test, model):\n",
      "    X_train, std = standardize(X_train)\n",
      "    X_test = std.transform(X_test)\n",
      "\n",
      "    X_train, pca = get_pca(X_train, 20)\n",
      "    X_test = pca.transform(X_test)\n",
      "\n",
      "    store_predictions = []\n",
      "    for i in range((Y_train.shape)[1]):\n",
      "        model.fit(X_train, Y_train[:, i])\n",
      "        P = model.predict(X_test)\n",
      "        store_predictions.append(P)\n",
      "\n",
      "    store_predictions = np.array(store_predictions)\n",
      "    store_predictions = np.matrix(store_predictions).T\n",
      "    store_predictions = np.array(store_predictions)\n",
      "    return store_predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dilution_dependant_prediction(X_train, Y_train, X_test, dils, model):\n",
      "    # TODO - repair\n",
      "    X_train, std = standardize(X_train)\n",
      "    X_test = std.transform(X_test)\n",
      "\n",
      "    X_train, pca = get_pca(X_train, 20)\n",
      "    X_test = pca.transform(X_test)\n",
      "\n",
      "    store_predictions = []\n",
      "    for i in range((Y_train.shape)[1]):\n",
      "        model.fit(X_train, Y_train[:, i])\n",
      "        P = model.predict(X_test)\n",
      "        store_predictions.append(P)\n",
      "\n",
      "    store_predictions = np.array(store_predictions)\n",
      "    store_predictions = np.matrix(store_predictions).T\n",
      "    store_predictions = np.array(store_predictions)\n",
      "    return store_predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "RUN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RUN 1\n",
      "# cid, rest\n",
      "X_cid_rest = getX()\n",
      "# cid, dilution, rest\n",
      "Y_cid_dil_rest, head = getY()\n",
      "# predict info\n",
      "toPredict = getPredict()\n",
      "# Create access to chemical informations via CID\n",
      "X_dict_by_cid = dict([(i[0], i[1:]) for i in X_cid_rest])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RUN 2\n",
      "# Average\n",
      "Y_cid_dil_rest_avg = avg_median(Y_cid_dil_rest)\n",
      "# Unique dillutions\n",
      "unique_dils = np.unique(Y_cid_dil_rest[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Optional features"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# RUN OPTIONAL\n",
      "# Compute models in advance based on the dilutions\n",
      "dils_models = learn_models(X_dict_by_cid, Y_cid_dil_rest_avg, unique_dils)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# RUN OPTIONAL\n",
      "# Make a prediction with models, that are computed in advance\n",
      "store_predictions = []\n",
      "for pr in toPredict:\n",
      "    cid = pr[0]\n",
      "    dil = pr[1]\n",
      "\n",
      "    X_to_predict = X_dict_by_cid[cid]        \n",
      "    scalar_int_ple, scalar_rest, pca_int_ple, pca_rest, models_list = dils_models[int(dil)]\n",
      "\n",
      "    # Standardize\n",
      "    if not scalar_int_ple == None:\n",
      "        X_to_predict_int_ple = scalar_int_ple.transform(X_to_predict)\n",
      "        X_to_predict_rest = scalar_rest.transform(X_to_predict)\n",
      "\n",
      "    # Pca\n",
      "    X_to_predict_int_ple = pca_int_ple.transform(X_to_predict)\n",
      "    X_to_predict_rest = pca_rest.transform(X_to_predict)\n",
      "\n",
      "    rezult = []\n",
      "    for i in range(len(models_list)):\n",
      "        model = models_list[i]\n",
      "        if i < 2:\n",
      "            X_to_predict = X_to_predict_int_ple\n",
      "        else:\n",
      "            X_to_predict = X_to_predict_rest\n",
      "\n",
      "        p = model.predict(X_to_predict)\n",
      "        rezult += [p[0]]\n",
      "    store_predictions += [np.array(rezult)]\n",
      "store_predictions = np.array(store_predictions)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# RUN OPTIONAL\n",
      "write_to_file2(toPredict[:, 0], store_predictions, head, \"gbr_1\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start cross validation\n",
      "\n",
      "#model = linear_model.Ridge()\n",
      "model = linear_model.RidgeCV()\n",
      "#model = linear_model.ElasticNetCV()\n",
      "#model = linear_model.ElasticNet()\n",
      "#model = ensemble.RandomForestRegressor(n_estimators=50, max_depth=None, min_samples_split=5, random_state=0, n_jobs=1)\n",
      "#model = ensemble.GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')\n",
      "X = np.array([X_dict_by_cid[cid] for cid in Y_cid_dil_rest_avg[:,0]])\n",
      "Y = Y_cid_dil_rest_avg[:, 2:]\n",
      "CV(X, Y, model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start new fold\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.769853764243\n",
        "Start new fold\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.87623216646\n",
        "Start new fold\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.64011366436\n",
        "Start new fold\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.90380540442\n",
        "Start new fold\n",
        "Vmesni ................."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.74702495939\n",
        "FINAL ................. 1.98740599178\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Predict real data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict real data\n",
      "X_pred = [X_dict_by_cid[cid] for cid, dil in toPredict]\n",
      "rezult = prediction(X, Y, X_pred, model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write into file\n",
      "write_to_file2(toPredict[:, 0], rezult, head, \"ridge_2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Null distribution of out data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.stats import pearsonr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_nan(l):\n",
      "    pc = []\n",
      "    for i in l:\n",
      "        if not np.isnan(i):\n",
      "            pc += [i]\n",
      "    return pc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([X_dict_by_cid[cid] for cid in Y_cid_dil_rest_avg[:,0]])\n",
      "Y = Y_cid_dil_rest_avg[:, 2]  # take one Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc = [np.abs(pearsonr(X[:, i], Y)[0]) for i in range(X.shape[1])]\n",
      "pc = remove_nan(pc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(pc, 50, color=\"yellow\", normed=True);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0xb744c50>"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.copy(Y)\n",
      "np.random.seed(42)\n",
      "pc_null = []\n",
      "for i in range(5):\n",
      "    np.random.shuffle(y)\n",
      "    pc_null.extend([np.abs(pearsonr(X[:, i], y)[0]) for i in range(X.shape[1])])\n",
      "    \n",
      "pc_null = remove_nan(pc_null)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(pc_null, 50, color=\"yellow\", normed=True);\n",
      "p = 0.01\n",
      "threshold = np.sort(pc_null)[(1-p)*len(pc_null)]\n",
      "plt.vlines(threshold, plt.ylim()[0], plt.ylim()[1], lw=3, color=\"k\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wMXmq2WuBAw5AAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x8a54f70>"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}