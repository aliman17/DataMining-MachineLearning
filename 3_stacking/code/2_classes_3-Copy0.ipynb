{
 "metadata": {
  "name": "",
  "signature": "sha256:02de1f5783e7cbbba2e2dafe38108d3bb43a959a60d0e78832050bbc30b1ab66"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import\n",
      "from collections import defaultdict\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "import pylab as P\n",
      "import Orange\n",
      "import random\n",
      "from sklearn import decomposition\n",
      "from sklearn import linear_model\n",
      "from sklearn import ensemble\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "import scipy\n",
      "import math\n",
      "import copy\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stringTOfloat(matrix):\n",
      "    \"\"\"Cast string values of a matrix into float values\"\"\"\n",
      "    matrix1 = []\n",
      "    for pos in range(len(matrix)):\n",
      "        i = matrix[pos]\n",
      "        #i[i == ''] = 0.0\n",
      "        i = i.astype(np.float)\n",
      "        matrix1.append(i)\n",
      "    return np.array( matrix1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def NANto0(matrix):\n",
      "    # Daj vse NAN na 0 -> ni ok, ampak za zacetek bo ok\n",
      "    for i in range(len(matrix)):\n",
      "        for j in range(len(matrix[i])):\n",
      "            if np.isnan(matrix[i,j]):\n",
      "                matrix[i,j] = 0\n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(name):\n",
      "    file1 = open(name, \"rU\" )\n",
      "    Y = []\n",
      "    for aRow in file1:\n",
      "        Y.append(aRow.split('\\t'))\n",
      "    file1.close()\n",
      "    return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse dilution and get denominator\n",
      "def get_dilution_denominator( string ):\n",
      "    i = 0\n",
      "    # Get rid of numerator\n",
      "    while ( string[i] != '/' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Get rid of '/'\n",
      "    while ( string[i] != '1' and i < len(string) ):\n",
      "        i += 1\n",
      "        \n",
      "    # Count zeros in denominator\n",
      "    n_zeros = 0\n",
      "    for j in range(i, len(string)):\n",
      "        if string[j] == '0':\n",
      "            n_zeros += 1\n",
      "            \n",
      "    return 10**n_zeros "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getX():\n",
      "    X = getData(\"../data/molecular_descriptors_data.txt\")\n",
      "    \n",
      "    # remove header\n",
      "    X = np.array(X[1:])\n",
      "    X = stringTOfloat(X)\n",
      "    # set Nan to 0\n",
      "    X = NANto0(X)\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getY():\n",
      "    Y = getData(\"../data/TrainSet-hw2.txt\")\n",
      "    \n",
      "    # header\n",
      "    head = Y[0]\n",
      "    \n",
      "    # remove header\n",
      "    Y = np.array(Y[1:])\n",
      "    \n",
      "    # get CID, get dil\n",
      "    cids = np.matrix(stringTOfloat(Y[:,0]))\n",
      "    dils = np.matrix([get_dilution_denominator(dil) for dil in Y[:,4]])\n",
      "   \n",
      "    # from \n",
      "    Y_rest = np.array(Y[:, 6:]) \n",
      "    Y_rest = stringTOfloat(Y_rest)\n",
      "    \n",
      "    Y_cid_dil_rest = np.hstack((cids.T,dils.T, Y_rest))\n",
      "    Y_cid_dil_rest = np.array(Y_cid_dil_rest)\n",
      " \n",
      "    \n",
      "    return Y_cid_dil_rest, head\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avg_median(Y_cid_dil_rest):\n",
      "    \n",
      "    cids = Y_cid_dil_rest[:, 0]\n",
      "    dils = Y_cid_dil_rest[:, 1]\n",
      "    # average\n",
      "    # get cids\n",
      "    cids_unique = np.unique(np.array(cids))\n",
      "    \n",
      "    # for each cid store avg value for all attributes\n",
      "    cid_avg = []\n",
      "    for cid in cids_unique:\n",
      "        cid_samples = Y_cid_dil_rest[ Y_cid_dil_rest[ :, 0 ] == cid ]\n",
      "        dil_low = cid_samples[0][1] \n",
      "        dil_high = cid_samples[1][1] \n",
      "        cid_samples_rest = np.matrix(cid_samples[:, 2:])  # remove cid and dil  \n",
      "        cid_samples_rest = np.array(cid_samples_rest[0::2].T)\n",
      "        # average\n",
      "        avg_low = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest]\n",
      "        avg_high = [np.mean(column[~np.isnan(column)]) for column in cid_samples_rest]\n",
      "        # concatenate cid with average values\n",
      "        cid_avg.append( np.hstack(([cid, dil_low], avg_low)) )\n",
      "        cid_avg.append( np.hstack(([cid, dil_high], avg_high)) )\n",
      "        \n",
      "    cid_avg = np.array( cid_avg )\n",
      "    return cid_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPredict():\n",
      "    P = getData(\"../data/predict.txt\")\n",
      "    \n",
      "    P = np.array(P)\n",
      "    \n",
      "    # get CID\n",
      "    cids = stringTOfloat(P[:,0])\n",
      "    dils = [get_dilution_denominator(dil) for dil in P[:,1]]\n",
      "    \n",
      "    P = []\n",
      "    for i in range( len(cids) ):\n",
      "        P.append((cids[i], dils[i]))\n",
      "    return np.array(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file(cid_preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../results/'+name+'.txt','w')\n",
      "    for cid, pred in cid_preds:\n",
      "        for i in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[i])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[i]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()\n",
      "    \n",
      "def write_to_file2(cids, preds, head, name):\n",
      "    head = head[6:] # remove labels for attributes that are not needed\n",
      "    head[-1] = (head[-1])[:-1]  # remove \\n at the end of head labels\n",
      "    f = open('../results/'+name+'.txt','w')\n",
      "    for i in range(len(cids)):\n",
      "        cid = cids[i]\n",
      "        pred = preds[i]\n",
      "        for j in range( len(pred) ):\n",
      "            f.write(str(int(cid)))   # change float to int then to string\n",
      "            f.write('\\t')\n",
      "            f.write(head[j])\n",
      "            f.write('\\t')\n",
      "            f.write(str(round(float(pred[j]), 6)))\n",
      "            f.write('\\n')\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NORM_STD = [ 0.18, 0.16, 0.06 ] #an average of normalizatin_costs outputs)\n",
      "#means were 0 (as expected for Pearson correlation)\n",
      "\n",
      "def normalization_consts(real):\n",
      "    \"\"\" Obtain the gold-standard deviation for our test and\n",
      "    leaderboard data sets. \"\"\"\n",
      "    permres = []\n",
      "    permuted = real\n",
      "    for i in range(10000):\n",
      "        permuted = np.random.permutation(permuted)\n",
      "        permres.append(evaluate_r(real, permuted))\n",
      "    permres = np.array(permres)\n",
      "    return np.mean(permres, axis=0), np.std(permres, axis=0)\n",
      "\n",
      "def pearson(x,y):\n",
      "    x,y = np.array(x), np.array(y)\n",
      "    anynan = np.logical_or(np.isnan(x), np.isnan(y))\n",
      "    r = scipy.stats.pearsonr(x[~anynan],y[~anynan])[0]\n",
      "    return 0. if math.isnan(r) else r\n",
      "\n",
      "def final_score(rs):\n",
      "    zs = rs/NORM_STD\n",
      "    return np.mean(zs)\n",
      "\n",
      "def evaluate_r(prediction, real):\n",
      "    userscores = prediction\n",
      "    realscores = real\n",
      "    rint = pearson(userscores[:,0], realscores[:,0])\n",
      "    rval = pearson(userscores[:,1], realscores[:,1])\n",
      "    rdecall = [ pearson(userscores[:,i], realscores[:,i]) for i in range(2,21) ]\n",
      "    rdec = np.mean(rdecall)\n",
      "    return np.array([rint, rval, rdec])\n",
      "\n",
      "def evaluate(prediction, real):\n",
      "    score = evaluate_r(prediction, real)\n",
      "    return final_score(score)\n",
      "\n",
      "def my_evaluate(prediction, real):\n",
      "    return pearson(prediction, real)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def my_cross_validation(X, y, model):\n",
      "    k = 3\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(y), n_folds=k, shuffle=True)\n",
      "    for train_index, test_index in kf:\n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = y[train_index], y[test_index]\n",
      "        # Predict\n",
      "        model.fit(X_train, Y_train)\n",
      "        P = model.predict(X_test)\n",
      "        # Evaluate\n",
      "        score = my_evaluate(P, Y_test)\n",
      "        S.append( score )\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_cross_validation_Y(X, Y, model, folds=5, print_=False):\n",
      "\n",
      "    k = folds\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(Y), n_folds=k, shuffle=True)\n",
      "    for train_index, test_index in kf:\n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
      "        # Predict\n",
      "        model.fit(X_train, Y_train)\n",
      "        P = model.predict(X_test)\n",
      "        # Evaluate\n",
      "        score = evaluate_r(P, Y_test)\n",
      "        S.append( final_score(score) )\n",
      "        if print_:\n",
      "            print(final_score(score))\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Multi cross validation\n",
      "def my_cross_validation_models(X, y, models, folds=5):\n",
      "   \n",
      "    # y combined with folds\n",
      "    y_real = np.array([])\n",
      "    # prediction, combined with fold for each model\n",
      "    Y_pred = []\n",
      "    for model in models:\n",
      "        Y_pred += [np.array([])]\n",
      "        \n",
      "    k = folds\n",
      "    S = 0\n",
      "    kf = cross_validation.KFold(len(y), n_folds=k, shuffle=True)\n",
      "    for train_index, test_index in kf:\n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = y[train_index], y[test_index]\n",
      "\n",
      "        y_real = np.hstack((y_real, Y_test))\n",
      "\n",
      "        # Predict\n",
      "        different_model_predicitons = []\n",
      "        for i in range( len(models) ):\n",
      "            model = models[i]\n",
      "            model.fit(X_train, Y_train)\n",
      "            P = model.predict(X_test)\n",
      "            Y_pred[i] = np.hstack( (Y_pred[i], P) )\n",
      "    # y and Y_pred is build \n",
      "    \n",
      "    return y_real, np.array(np.matrix(Y_pred).T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "RUN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get X of a form: cid, rest\n",
      "X_cid_rest = getX()\n",
      "# Get Y of a form: cid, dilution, rest\n",
      "Y_cid_dil_rest, head = getY()\n",
      "# Get data to predict of a form: (cid, dil)\n",
      "toPredict = getPredict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Dict:  <cid, chemical data without cid>\n",
      "X_dict_by_cid = dict([(i[0], i[1:]) for i in X_cid_rest])\n",
      "# Average by cid and dilution\n",
      "Y_cid_dil_rest_avg = avg_median(Y_cid_dil_rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make inner join X and Y\n",
      "X = np.array([np.hstack(( cid_dil[1], X_dict_by_cid[cid_dil[0]] )) for cid_dil in Y_cid_dil_rest_avg[:,0:2]])\n",
      "# Remove cid and dil\n",
      "Y = Y_cid_dil_rest_avg[:, 2:]   \n",
      "# Predict\n",
      "X_predict = [np.hstack(( dil, X_dict_by_cid[cid] )) for cid, dil in toPredict]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shuffle lines, we get more real result\n",
      "z = [i for i in range(Y.shape[0])]\n",
      "X_random = [0] * X.shape[0]\n",
      "Y_random = [0] * Y.shape[0]\n",
      "\n",
      "random.shuffle(z)\n",
      "for i in range(len(z)):\n",
      "    X_random[i] = X[z[i]]\n",
      "    Y_random[i] = Y[z[i]]\n",
      "X = np.array(X)\n",
      "Y = np.array(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca = decomposition.PCA(n_components=20)\n",
      "X = pca.fit_transform(X)  \n",
      "X_predict = pca.transform(X_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#N = normalization_consts(Y)\n",
      "#NORM_STD = N[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def combine_predictions(predicitons):\n",
      "    return np.sum(predicitons, axis=1) / predicitons.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "class Learner():\n",
      "    def __init__(self, model, pca=False, components=20, std=True, **args):\n",
      "        self.model = model(**args)\n",
      "        self.pcaBool=pca\n",
      "        self.stdBool=std\n",
      "        self.pca=None\n",
      "        self.components=components\n",
      "        self.std=None\n",
      "        self.args=args\n",
      "        \n",
      "    def fit(self, dataX, dataY):\n",
      "        if self.pcaBool:\n",
      "            self.pca = decomposition.PCA(n_components=self.components)\n",
      "            dataX = self.pca.fit_transform(dataX)  \n",
      "        if self.stdBool:\n",
      "            self.std = preprocessing.StandardScaler()\n",
      "            dataX = self.std.fit_transform(dataX)\n",
      "        return self.model.fit(dataX, dataY)\n",
      "    \n",
      "    def predict(self, X):\n",
      "        if self.pcaBool:\n",
      "            X = self.pca.transform(X)\n",
      "        if self.stdBool:\n",
      "            X = self.std.transform(X)\n",
      "        return self.model.predict(X)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Stacking():\n",
      "    def __init__(self, models, aggreg_model=None):\n",
      "        self.models = models\n",
      "        self.aggregation = aggreg_model\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # Get aggregation function\n",
      "        y2, Y_pred2 = my_cross_validation_models(X, y, self.models)\n",
      "\n",
      "        # Combine models with reggression\n",
      "        if self.aggregation != None:\n",
      "            self.aggregation.fit(Y_pred2, y2)\n",
      "        \n",
      "        # Nauci modele\n",
      "        for model in self.models:\n",
      "            model.fit(X, y)\n",
      "            \n",
      "    def predict(self, X):\n",
      "        predict_list = []\n",
      "        for model in self.models:\n",
      "            P = model.predict(X)\n",
      "            predict_list += [P]\n",
      "        Ys = np.array(np.matrix(predict_list).T)\n",
      "        if self.aggregation == None:\n",
      "            return combine_predictions(Ys)\n",
      "        return self.aggregation.predict(Ys)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Stacking21():\n",
      "    \"\"\"Stacking for 21 atributes\"\"\"\n",
      "    def __init__(self, models, aggr_model=None):\n",
      "        self.models = models\n",
      "        self.aggregation = aggr_model\n",
      "        self.models21 = None\n",
      "    def fit(self, X, Y):\n",
      "        self.models21 = []\n",
      "        for i in range(Y.shape[1]):\n",
      "            print(i)\n",
      "            models = copy.deepcopy(self.models)\n",
      "            aggregation = copy.deepcopy(self.aggregation)\n",
      "            stck = Stacking(models, aggregation)\n",
      "            stck.fit(X, Y[:, i])\n",
      "\n",
      "            self.models21 += [stck]\n",
      "    \n",
      "    def predict(self, X_predict):\n",
      "        Ys = []\n",
      "        for i in range(Y.shape[1]):\n",
      "            stck = self.models21[i]\n",
      "            Ys += [ stck.predict(X_predict) ]\n",
      "        Ys = np.array(np.matrix(Ys).T)\n",
      "        return Ys\n",
      "    \n",
      "    def copy_models(self, models):\n",
      "        models2 = []\n",
      "        for model in models:\n",
      "            models2.append(copy.deepcopy())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "21 models "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge2 = linear_model.Ridge()\n",
      "ridgeCV2 = linear_model.RidgeCV()\n",
      "lasso2 = linear_model.Lasso()\n",
      "elasticCV2 = linear_model.ElasticNetCV()\n",
      "elastic2 = linear_model.ElasticNet()\n",
      "forest2 = ensemble.RandomForestRegressor(n_estimators=10, max_depth=None, min_samples_split=5, random_state=0, n_jobs=1)\n",
      "boost2 = ensemble.GradientBoostingRegressor(n_estimators=10, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')\n",
      "tree2 = ensemble.ExtraTreesRegressor(n_estimators=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linear_model.ElasticNet == linear_model.ElasticNet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge = Learner(linear_model.Ridge)\n",
      "ridgeCV = Learner(linear_model.RidgeCV)\n",
      "lasso = Learner(linear_model.Lasso)\n",
      "elasticCV = Learner(linear_model.ElasticNetCV)\n",
      "elastic = Learner(linear_model.ElasticNet)\n",
      "forest = Learner(ensemble.RandomForestRegressor, n_estimators=200)\n",
      "boost = Learner(ensemble.GradientBoostingRegressor, n_estimators=200)\n",
      "tree = Learner(ensemble.ExtraTreesRegressor, n_estimators=500)\n",
      "bagging = Learner(ensemble.BaggingRegressor, n_estimators=500)\n",
      "aggr = linear_model.Ridge()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stck = Stacking21([tree, bagging], elastic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_cross_validation_Y(X, Y, stck, folds=3, print_=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6.09822343917"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-32-260e360cd9df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_cross_validation_Y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-12-c62485473622>\u001b[0m in \u001b[0;36mmy_cross_validation_Y\u001b[1;34m(X, Y, model, folds, print_)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-23-9dd671e4ac5f>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0maggregation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mstck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mstck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels21\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-22-54ea0c08acef>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Get aggregation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_cross_validation_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Combine models with reggression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-13-c01eb3517830>\u001b[0m in \u001b[0;36mmy_cross_validation_models\u001b[1;34m(X, y, models, folds)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mY_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-21-c61072e935a0>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataX, dataY)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mdataX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, monitor)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \"\"\"\n\u001b[0;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, monitor)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, random_state,\n\u001b[1;32m--> 783\u001b[1;33m                                     begin_at_stage, monitor)\n\u001b[0m\u001b[0;32m    784\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, random_state, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_mask,\n\u001b[1;32m--> 835\u001b[1;33m                                      criterion, splitter, random_state)\n\u001b[0m\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_mask, criterion, splitter, random_state)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             tree.fit(X, residual,\n\u001b[1;32m--> 572\u001b[1;33m                      sample_weight=sample_weight, check_input=False)\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stck2 =  Stacking21([tree, bagging], elastic)\n",
      "stck2.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Write into file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ys = stck2.predict(X_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ys.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "(80, 21)"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write into file\n",
      "write_to_file2(toPredict[:, 0], Ys, head, \"STACKING_tree_bagg_pca_std_elasticAggr_500_dreves\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}