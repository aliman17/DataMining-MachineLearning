{
 "metadata": {
  "name": "",
  "signature": "sha256:87f0d67afdbf587f54f8eeb568dc9d4bdc5beb57500c08040c1ce9acfbcc51b7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "from sklearn import decomposition\n",
      "from sklearn import datasets\n",
      "import numpy as np\n",
      "import scipy as sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_in = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "\n",
      "y_train_in = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "y_train_in = np.array([int(c[-2]) for c in y_train_in])  # Parse classes from Class_1 into 1\n",
      "\n",
      "NUM_OF_CLASSES = len( np.unique(y_train_in))  # Warning: number of classes must go from 1 to n\n",
      "\n",
      "X_test_in = np.loadtxt(open(\"../data/test.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "iris = datasets.load_iris()\n",
      "X_train_in = iris.data\n",
      "y_train_in = iris.target.T"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preprocesse Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shuffle\n",
      "XY = np.hstack((X_train_in, np.matrix(y_train_in).T))\n",
      "np.random.shuffle(XY)\n",
      "X_train = XY[:, :X_train_in.shape[1]]\n",
      "y_train = XY[:, X_train_in.shape[1]:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I = np.identity(NUM_OF_CLASSES)\n",
      "y_train = np.array( [ I[y[0,0]-1] for y in y_train])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Normalize\n",
      "norm = preprocessing.Normalizer()\n",
      "X_train = norm.fit_transform(X_train_in)\n",
      "X_test = norm.transform(X_test_in)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(50000, 9)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
        "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
        "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(50000, 93)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train[:10,:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[ 0.06388766,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.01546166,  0.        ,  0.        ,  0.01546166],\n",
        "       [ 0.11527808,  0.05763904,  0.        ,  0.        ],\n",
        "       [ 0.25819889,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "       [ 0.        ,  0.05661385,  0.05661385,  0.1132277 ]])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Helper Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_ones(X):\n",
      "    return np.column_stack((X, np.ones(X.shape[0])))\n",
      "\n",
      "def add_one(X):\n",
      "    return np.append(X, 1)\n",
      "\n",
      "def add_zero(X):\n",
      "    return np.append(X, 0)\n",
      "\n",
      "def del_one(X):\n",
      "    return X[:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Sigmoid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    return 1/(1+np.exp(-z))\n",
      "\n",
      "def sigmoid_derivative(z):\n",
      "    return np.multiply(z , 1 - z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Tansigmoid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tansigmoid(z):\n",
      "    return ( np.exp(z) - np.exp(-z) ) / (np.exp(z) + np.exp(-z))\n",
      "\n",
      "def tansigmoid_derivative(z):\n",
      "    return 1 - tansigmoid(z)**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Arctan (my try)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def arctan(z):\n",
      "    return np.arctan(2*z) / np.pi + 1/2\n",
      "\n",
      "def arctan_derivative(z):\n",
      "    return 2 / (((2*z)**2 + 1) * np.pi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = np.array([1,2,3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grad_approx(J, thetas, e=1e-5):\n",
      "        return np.array([(J(thetas+eps) - J(thetas-eps))/(2*e)\n",
      "                         for eps in np.identity(len(thetas)) * e])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(tansigmoid_derivative(m))\n",
      "grad_approx(tansigmoid, m).diagonal()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.41997434  0.07065082  0.00986604]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([ 0.41997434,  0.07065082,  0.00986604])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(arctan_derivative(m))\n",
      "grad_approx(arctan, m).diagonal()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.12732395  0.03744822  0.01720594]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([ 0.12732395,  0.03744822,  0.01720594])"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetClassifier():\n",
      "    \"\"\"Neural network classifier based on a set of binary classifiers.\"\"\"\n",
      "    def __init__(self, h, thetas):\n",
      "        self.thetas = thetas  # model parameters\n",
      "        self.h = h\n",
      "        \n",
      "    def predict(self, X):\n",
      "        return np.array( [ self.h(x_, self.thetas) for x_ in X])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetLearner():\n",
      "    def __init__(self, arch, g=sigmoid, g_derivative=sigmoid_derivative, lambda_=1e-5):\n",
      "        self.arch = arch\n",
      "        self.n_levels = len(arch)\n",
      "        \n",
      "        self.g = g\n",
      "        self.g_derivative = g_derivative\n",
      "        \n",
      "        self.lambda_ = lambda_\n",
      "        self.theta_shape = np.array([ ( arch[i] + 1, arch[i + 1]) for i in range( len( arch) - 1)])\n",
      "        ind = np.array( [ sh1 * sh2 for sh1, sh2 in self.theta_shape])\n",
      "        self.theta_ind = np.cumsum( ind[:-1])  # last index falls out of the boundary\n",
      "        self.theta_len = sum(ind)\n",
      "        self.seed = False\n",
      "    \n",
      "    def init_thetas(self, epsilon=1e-5):\n",
      "        \"\"\"Return thetas with random values\"\"\"\n",
      "        if self.seed: \n",
      "            np.random.seed(42)\n",
      "        return np.random.rand(self.theta_len) * 2 * epsilon - epsilon\n",
      "    \n",
      "    def shape_thetas(self, thetas):\n",
      "        \"\"\"Return list of thetas at particular level\"\"\"\n",
      "        t = np.split(thetas, self.theta_ind)\n",
      "        return np.array( [t[i].reshape(shape) for i, \n",
      "                          shape in enumerate(self.theta_shape)])\n",
      "    \n",
      "    def feedforward(self, a_, thetas):\n",
      "        \"\"\"Feed forward, prediction, add ones to the end for bias\"\"\"\n",
      "        thetas = self.shape_thetas(thetas)\n",
      "        activations = [0] * self.n_levels\n",
      "        activations[0] = a_\n",
      "        for i in range( 1, self.n_levels): \n",
      "            activations[i] = self.g(np.dot(add_one(activations[i-1]), thetas[i-1]))\n",
      "        return np.array(activations)\n",
      "    \n",
      "    def backprop(self, x_, y_, thetas):\n",
      "        \"\"\"Add bias to the end\"\"\"\n",
      "        activations = self.feedforward( x_, thetas)\n",
      "        thetas = self.shape_thetas( thetas)\n",
      "        # output error\n",
      "        err = - np.multiply( y_ - activations[-1],  \n",
      "                             self.g_derivative( activations[-1])) \n",
      "               \n",
      "        errors = [0] * self.n_levels\n",
      "        errors[self.n_levels - 1] = err \n",
      "        \n",
      "        levels = list(range(0, self.n_levels-1))\n",
      "        for l in levels[::-1]:  # reverse\n",
      "            th_ = np.matrix(err) * thetas[l].T \n",
      "            ac_ = add_one( activations[l] ) # add bias\n",
      "            ac_ = np.multiply( ac_, (1 - ac_))\n",
      "            errors[l] = np.array( np.multiply( th_, ac_) )[0]\n",
      "            err = del_one(errors[l])\n",
      "\n",
      "        return np.array(errors), activations\n",
      "    \n",
      "    def l2_reg( self, thetas):\n",
      "        thetas2 = thetas * thetas\n",
      "        thetas2 = self.shape_thetas( thetas2)\n",
      "        sum_ = 0\n",
      "        for levelthetas in thetas2:\n",
      "            for i in range( levelthetas.shape[0] - 1):\n",
      "                sum_ += sum( levelthetas[i])\n",
      "        return sum_ * self.lambda_ / 2\n",
      "    \n",
      "    def l2_reg_grad( self, thetas):\n",
      "        thetasModified = self.shape_thetas( thetas)\n",
      "        for i in range( len( thetasModified)):\n",
      "            thetasModified[i][-1] *= 0\n",
      "        return self.lambda_ * thetasModified\n",
      "    \n",
      "    # TODO self.m, self.X, self.Y, self.lambda_\n",
      "    def J(self, thetas):\n",
      "        sum_ = 0\n",
      "        for i in range( self.X.shape[0]):\n",
      "            sum_ += sum((self.feedforward( self.X[i], thetas)[-1] - self.Y[i])**2)\n",
      "        sum_ = sum_ / (2 * self.X.shape[0]) + self.l2_reg( thetas)\n",
      "        return sum_\n",
      "\n",
      "    def Jgrad(self, thetas):\n",
      "        errorsANDactivations = map( lambda z: self.backprop( z[0], z[1], thetas), zip( self.X, self.Y))\n",
      "        grad = [0] * (self.n_levels-1)\n",
      "        for errors, activations in errorsANDactivations:\n",
      "            for l in range(self.n_levels-1):\n",
      "                err = del_one(errors[l+1]) if l != self.n_levels-2 else errors[l+1]\n",
      "                cur_grad = np.dot(np.matrix( add_one(activations[l]) ).T, np.matrix(err))\n",
      "                grad[l] = grad[l] + cur_grad\n",
      "        \n",
      "        grad = np.array(grad) / self.X.shape[0] + self.l2_reg_grad( thetas)\n",
      "        flatten = np.array([])\n",
      "        for matrix in grad:\n",
      "            flatten = np.append(flatten, matrix.ravel())\n",
      "        return flatten\n",
      "        \n",
      "    def grad_approx(self, thetas, e=1e-1):\n",
      "        return np.array([(self.J(thetas+eps) - self.J(thetas-eps))/(2*e)\n",
      "                         for eps in np.identity(len(thetas)) * e]).ravel()\n",
      "    \n",
      "    def set_data( self, X, Y, thetas=None):\n",
      "        self.X = X\n",
      "        self.Y = Y\n",
      "        self.thetas = thetas if thetas != None else self.init_thetas()\n",
      "    \n",
      "    def fit(self, X, Y, thetas=None):\n",
      "        \"\"\" x_ is a vector, y is a class between 1 and sth\"\"\"\n",
      "        self.set_data(X, Y, thetas)\n",
      "        self.seed = False\n",
      "        thetas, _, _ = fmin_l_bfgs_b(func = self.J,\n",
      "                                           x0 = self.thetas,\n",
      "                                           fprime = self.Jgrad,\n",
      "                                           factr=10,\n",
      "                                           maxiter=1000)   \n",
      "        return thetas\n",
      "    \n",
      "    def predict(self, x_, thetas):\n",
      "        return self.feedforward( x_, thetas)[-1]\n",
      "        \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 5\n",
      "X = X_train[0:threshold, :4]\n",
      "Y = y_train[0:threshold]\n",
      "#lr = NeuralNetLearner([X.shape[1], 2,  9], tansigmoid, tansigmoid_derivative)  # use this for tangens\n",
      "#lr = NeuralNetLearner([X.shape[1], 2,  9], arctan, arctan_derivative)\n",
      "lr = NeuralNetLearner([X.shape[1], 2,  9])  # use this for logistic funciton\n",
      "r = lr.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test cost function\n",
      "print( \"Cost function:\", lr.J(lr.thetas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cost function: 1.12499481066\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# Test atributes and some minor functions of a learner\n",
      "\n",
      "print( \"Testing shape\\n\", lr.theta_shape)\n",
      "print( \"Testing indices\\n\", lr.theta_ind)\n",
      "print( \"Testing theta lenght\\n\", lr.theta_len)\n",
      "print( \"Testing theta shape\\n\", lr.shape_thetas( thetas))"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# Test feed forward\n",
      "\n",
      "print( \"Test feed forward:\")\n",
      "print( lr.feedforward(lr.x_, lr.thetas))"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# Test back propagation\n",
      "\n",
      "print( \"Test errors and activations\")\n",
      "errors, acts = lr.backprop(lr.thetas)\n",
      "print( errors.shape, acts.shape)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test gradient function \n",
      "\n",
      "print( \"Grad. function:\", lr.Jgrad(lr.thetas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Grad. function: [ -1.08807477e-08  -1.49389837e-08   2.02472231e-10  -5.34238971e-09\n",
        "   2.92725988e-11  -5.91657723e-11  -9.78228698e-10  -2.20116074e-10\n",
        "  -4.09481745e-07  -6.41097285e-07   3.74997579e-02   6.24996354e-02\n",
        "   1.25000281e-02   6.24996152e-02   6.24993866e-02   3.74999472e-02\n",
        "   6.24997817e-02   3.74997361e-02   6.24995573e-02   3.74998327e-02\n",
        "   6.24997939e-02   1.25000800e-02   6.24997738e-02   6.24995450e-02\n",
        "   3.75000370e-02   6.24999403e-02   3.74998366e-02   6.24997158e-02\n",
        "   7.49997010e-02   1.24999617e-01   2.50001466e-02   1.24999577e-01\n",
        "   1.24999120e-01   7.50000975e-02   1.24999910e-01   7.49996865e-02\n",
        "   1.24999461e-01]\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test gradient approximation\n",
      "\n",
      "print( \"Grad. approx:\", lr.grad_approx(lr.thetas, e=1e-5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Grad. approx: [ -1.08801856e-08  -1.49324997e-08   1.99840144e-10  -5.35127498e-09\n",
        "   3.33066907e-11  -5.55111512e-11  -9.65894031e-10  -2.10942375e-10\n",
        "  -4.09494660e-07  -6.41109388e-07   3.74998696e-02   6.24999997e-02\n",
        "   1.25001533e-02   6.24999526e-02   6.24997827e-02   3.75000317e-02\n",
        "   6.24998829e-02   3.74998435e-02   6.24999026e-02   3.74998644e-02\n",
        "   6.25000248e-02   1.25001786e-02   6.24999778e-02   6.24998079e-02\n",
        "   3.75000416e-02   6.24999082e-02   3.74998640e-02   6.24999278e-02\n",
        "   7.49997323e-02   1.25000026e-01   2.50003330e-02   1.24999932e-01\n",
        "   1.24999592e-01   7.50000745e-02   1.24999792e-01   7.49997093e-02\n",
        "   1.24999832e-01]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test difference\n",
      "print( \"grad - grad.aprox =\", sum( lr.Jgrad(lr.thetas) - lr.grad_approx(lr.thetas, e=1e-5) ))  # = -2.310293595541139e-12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "grad - grad.aprox = -2.37685530643e-11\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Batch Sequential"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stohastic training:   size = 1\n",
      "# batch training:       size = num of samples \n",
      "# batch sequential:     otherwise\n",
      "class BatchSeq():\n",
      "    def __init__(self, learner, size=100, alpha=0.1):\n",
      "        self.learner = learner\n",
      "        self.size = size\n",
      "        self.alpha = alpha \n",
      "        \n",
      "    def fit_thetas(self, X, y_, thetas=None):\n",
      "        # num of samples = 1130 = 0, 100, ..., 900, 1000, 1130 (last block takes all remainded)\n",
      "        split = [ [lo, lo + self.size] \n",
      "                          for lo in range( 0, X.shape[0], self.size)\n",
      "                        ] if X.shape[0] >= self.size else [[0, 0]]\n",
      "        split[-1][-1] = X.shape[0]\n",
      "        counter = 0\n",
      "        for lo, hi in split:\n",
      "            print(counter)\n",
      "            counter += 1\n",
      "            thetas = self.learner.fit( X[lo:hi], y_[lo:hi], thetas)\n",
      "        return thetas\n",
      "    \n",
      "    def fit(self, X, y_):\n",
      "        eps = 1e-4\n",
      "        thetas = self.learner.init_thetas()\n",
      "        # run until the error is very small ... because lbfgs, we don't need this anymore\n",
      "        for i in range(1):\n",
      "            prev = thetas\n",
      "            thetas = self.fit_thetas(X, y_, thetas)\n",
      "            #if (sum( abs(thetas - prev) > eps ) == 0):\n",
      "            #    break\n",
      "        model = NeuralNetClassifier(self.learner.predict, thetas)\n",
      "        return model           \n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate(pred, real):\n",
      "    return metrics.log_loss(real, pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_cross_validation(X, Y, arch, lam, k=3):\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(Y), n_folds=k, shuffle=True)\n",
      "    for train_index, test_index in kf:\n",
      "        print(\"New circle\", arch)\n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
      "        \n",
      "        learner = NeuralNetLearner(arch, lambda_=lam)\n",
      "        bs = BatchSeq( learner, 100)\n",
      "        model = bs.fit(X_train, Y_train)\n",
      "        predicted = model.predict(X_test)\n",
      "        \n",
      "        # Evaluate\n",
      "        score = evaluate(predicted, Y_test)\n",
      "        print(\"Vmesni rezultat: \", score)\n",
      "        S.append( score )\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RUN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pca\n",
      "if True:\n",
      "    pca = decomposition.PCA(n_components=20)\n",
      "    X_train = pca.fit_transform(X_train)\n",
      "    X_test = pca.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X_train.shape, y_train.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 20) (50000, 9)\n"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Parameters to test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- lambda for regularization\n",
      "- levels\n",
      "- batchsequential size"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 50000\n",
      "X = X_train[:threshold, :]\n",
      "Y = y_train_extended[:threshold]\n",
      "\n",
      "\n",
      "# Because the input is much larger than output. Then it is good idea\n",
      "# to build hidden levels in a way that number of hidden states falls \n",
      "# from the length of the input till the length of the output. We need\n",
      "# to specify the length and then compute number off hidden neurons at\n",
      "# each level.\n",
      "\n",
      "lambdas = [0.1, 0.5, 1, 5]\n",
      "lengths = [2, 10, 20]\n",
      "\n",
      "for length in lengths:\n",
      "    \n",
      "    k = - (X_train.shape[1] - NUM_OF_CLASSES) / (length+1)\n",
      "    hidden = [ int( k * j + X_train.shape[1]) for j in range(1, length+1)]\n",
      "    arch = [X.shape[1]] + hidden + [NUM_OF_CLASSES]\n",
      "    \n",
      "    for lam in lambdas:\n",
      "        #score = my_cross_validation(X, Y, arch, lam)\n",
      "        score = 10\n",
      "        with open(\"crossval.txt\", \"a\") as myfile:\n",
      "            myfile.write(str(score)+\"\\t lambda=\"+str(lam)+\"\\t length=\"+str(length)+\"\\t arch=\"+str(arch)+\"\\n\")\n",
      "            myfile.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str([1,2,3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 233,
       "text": [
        "'[1, 2, 3]'"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_of_hidden_levels = 2\n",
      "hidden_size = 2\n",
      "\n",
      "hidden = [hidden_size for i in range(n_of_hidden_levels)]\n",
      "arch = [X.shape[1]] + hidden + [NUM_OF_CLASSES]\n",
      "\n",
      "print( my_cross_validation(X, Y, arch))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New circle\n",
        "0\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Vmesni rezultat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.55819360498\n",
        "New circle\n",
        "0\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Vmesni rezultat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.65681216199\n",
        "New circle\n",
        "0\n",
        "Starting lbfgs\n",
        "End lbfgs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1\n",
        "Starting lbfgs\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-225-f93fd950e301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmy_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0march\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-224-e3d2c0144530>\u001b[0m in \u001b[0;36mmy_cross_validation\u001b[1;34m(X, Y, arch, k)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchSeq\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-186-8c55a5ded954>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y_)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_thetas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[1;31m#if (sum( abs(thetas - prev) > eps ) == 0):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m#    break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-186-8c55a5ded954>\u001b[0m in \u001b[0;36mfit_thetas\u001b[1;34m(self, X, y_, thetas)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-180-4d62929c7a3c>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, thetas)\u001b[0m\n\u001b[0;32m    109\u001b[0m                                            \u001b[0mfprime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                                            \u001b[0mfactr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                                            maxiter=1000)   \n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"End lbfgs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 187\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    188\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    189\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, **unknown_options)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-180-4d62929c7a3c>\u001b[0m in \u001b[0;36mJgrad\u001b[1;34m(self, thetas)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0merrorsANDactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_levels\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m \u001b[1;32min\u001b[0m \u001b[0merrorsANDactivations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_levels\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdel_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_levels\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-180-4d62929c7a3c>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mJgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0merrorsANDactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_levels\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m \u001b[1;32min\u001b[0m \u001b[0merrorsANDactivations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-180-4d62929c7a3c>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, x_, y_, thetas)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;34m\"\"\"Add bias to the end\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_thetas\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# output error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-180-4d62929c7a3c>\u001b[0m in \u001b[0;36mfeedforward\u001b[1;34m(self, a_, thetas)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_levels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hidden = [30, 15]\n",
      "arch = [X_train.shape[1]] + hidden + [NUM_OF_CLASSES]\n",
      "learner = NeuralNetLearner(arch, lambda_=1e-5)\n",
      "bs = BatchSeq( learner, 50000)\n",
      "model = bs.fit(X_train, y_train)\n",
      "predicted = model.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = model.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_file(predicted, name):\n",
      "    answer = np.matrix(predicted.astype(str))\n",
      "    ids = np.matrix(range(1, answer.shape[0]+1))\n",
      "    answer = np.hstack((ids.T.astype(str), answer))\n",
      "    answer = np.vstack((np.array([\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]), answer))\n",
      "    answer = answer.tolist()\n",
      "    answer = \"\\n\".join( [\",\".join(line) for line in answer] )\n",
      "\n",
      "    fo = open(\"../results/\"+name+\".csv\", \"wt\")\n",
      "    fo.write(answer)\n",
      "    fo.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_to_file(predicted, \"batch1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adaptivni gradient, pri drugem stohasti\u010dnem primeru. \n",
      "Vsako iteracijo manj pristejemo. \n",
      "\n",
      "Lbfgs 1 iteracija za batch seq. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}