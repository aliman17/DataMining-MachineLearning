{
 "metadata": {
  "name": "",
  "signature": "sha256:d4b55b8879e4d8e58fd8f40c671fe217533c47cd28eb7230b2c50bedbe5ac28d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn import cross_validation\n",
      "from collections import deque\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "import copy\n",
      "import time\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUM_OF_CLASSES = 0\n",
      "def load_data1():\n",
      "    \"\"\"Load keggle\"\"\"\n",
      "    global NUM_OF_CLASSES\n",
      "    X_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "    X_test = np.loadtxt(open(\"../data/test.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "    \n",
      "    y_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "    y_train = np.array([int(c[-2])-1 for c in y_train])  # Parse classes from Class_1 into 1\n",
      "    return X_train, y_train, X_test\n",
      "\n",
      "def load_data2():\n",
      "    \"\"\"Load iris\"\"\"\n",
      "    iris = datasets.load_iris()\n",
      "    X_train = iris.data\n",
      "    y_train = iris.target.T\n",
      "    return X_train, y_train, None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = 1\n",
      "if data == 1:\n",
      "    X_train, Y_train, X_test = load_data1()\n",
      "else:\n",
      "    X_train, Y_train, X_test = load_data2()\n",
      "NUM_OF_CLASSES = len( np.unique(Y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preprocesse Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shuffle(X, Y):\n",
      "    ind = np.array(list(range(X.shape[0])))\n",
      "    np.random.shuffle(ind)\n",
      "    X = np.array( [ X[i] for i in ind] )\n",
      "    Y = np.array( [ Y[i] for i in ind] )\n",
      "    return X, Y \n",
      "X_train, Y_train = shuffle(X_train, Y_train)\n",
      "std = preprocessing.StandardScaler()\n",
      "X_train = std.fit_transform(X_train)\n",
      "X_test = std.transform(X_test)\n",
      "X_train = np.matrix(X_train)\n",
      "X_test = np.matrix(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binaryClassRepresentation(Y):\n",
      "    \"\"\" Class 1 write as 1,0,0,0,0,0,0,0,0, class 2 write as 0,1,0,0,0,0,0,0,0, ... \"\"\"\n",
      "    I = np.identity(NUM_OF_CLASSES)\n",
      "    Y = np.array( [ I[y] for y in Y])\n",
      "    return Y\n",
      "Y_train = binaryClassRepresentation(Y_train)\n",
      "Y_train = np.matrix(Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate(pred, real):\n",
      "    return metrics.log_loss(real, pred)\n",
      "\n",
      "\n",
      "def my_cross_validation(X, Y, model, k=3):\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(Y), n_folds=k, shuffle=False)\n",
      "    for train_index, test_index in kf:\n",
      "        print(\"New fold\")\n",
      "        start = time.time()  \n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
      "        \n",
      "        model.fit(X_train, Y_train)\n",
      "        predicted = model.predict(X_test)\n",
      "        # Evaluate\n",
      "        score = evaluate(predicted, Y_test)\n",
      "         \n",
      "        end = time.time()\n",
      "        \n",
      "        print(\"        Time:\", round(end - start, 2), \"s                                     ### Vmesni rezultat ###: \",  score)\n",
      "        sys.stdout.flush()\n",
      "        S.append( score )\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Init Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class InitModel():\n",
      "    def fit(self, X, Y):\n",
      "        self.Y = Y\n",
      "    def predict(self, X):\n",
      "        if len(X.shape) == 1:\n",
      "            return np.mean(self.Y, axis=0)\n",
      "        else:\n",
      "            return np.array(np.mean(self.Y, axis=0))[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 20\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "init = InitModel()\n",
      "init.fit(X, Y)\n",
      "\n",
      "init.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "array([ 0.  ,  0.25,  0.2 ,  0.1 ,  0.  ,  0.25,  0.05,  0.15,  0.  ])"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GradBoostLearner():\n",
      "    \"\"\"Gradient Boosting for Regression.\"\"\"\n",
      "\n",
      "    def __init__(self, learner, n_estimators=10, epsilon=1e-5, l_rate = 1, loss=\"log_loss\"):\n",
      "        self.n_estimators = n_estimators\n",
      "        self.learner = learner  # base learner\n",
      "        self.name = \"gb_est\" + str(self.n_estimators) + \"_\" + loss\n",
      "        self.epsilon = epsilon\n",
      "        self.l_rate = l_rate\n",
      "        losses = {\"huber\": self.grad_huber_loss, \n",
      "                  \"squared\": self.grad_squared_loss, \n",
      "                  \"abs\": self.grad_abs_loss,\n",
      "                  \"log_loss\": self.log_loss}\n",
      "        self.loss = losses[loss]\n",
      "        self.model_series = None\n",
      "\n",
      "    \n",
      "    def log_loss(self, real, pred):\n",
      "        \"\"\"Negative gradient for log loss\"\"\"\n",
      "        return metrics.log_loss(real, pred)\n",
      "    \n",
      "    def grad_squared_loss(self, y, f):\n",
      "        \"\"\"Negative gradiant for squared loss.\"\"\"\n",
      "        return y - f\n",
      "    \n",
      "    def grad_abs_loss(self, y, f):\n",
      "        \"\"\"Negative gradient for absolute loss.\"\"\"\n",
      "        return np.sign(y - f)\n",
      "    \n",
      "    def grad_huber_loss(self, y, f, delta=0.5):\n",
      "        \"\"\"Negative gradient for Huber loss.\"\"\"\n",
      "        r0 = y - f\n",
      "        r1 = delta * np.sign(r0)\n",
      "        return np.vstack((r0, r1)).T[np.arange(y.shape[0]), (np.abs(r0)>delta).astype(int)]\n",
      "    \n",
      "   \n",
      "    def softmax(self, X, axis = 1):\n",
      "        # Description: Function apply softmax on a vector\n",
      "        #\n",
      "        # Input:     \n",
      "        #\n",
      "        # Output:      \n",
      "        \n",
      "        X = np.exp( X )\n",
      "        SumX = np.sum( X, axis = axis )   # sum rows, because these are gonna be denumerators\n",
      "        X = X / SumX \n",
      "        return X\n",
      "\n",
      "    \n",
      "    def fit_all_classes(self, X, Y):\n",
      "        # Description: Function performs gradient boosting for ALL classes\n",
      "        #\n",
      "        # Input:       X     matrix of samples\n",
      "        #              Y     MATRIX of a classes identification\n",
      "        #\n",
      "        # Output:      List of fitted models that are used for classification.\n",
      "        \n",
      "        \n",
      "        # Prepare list of queues which are intended for NUM_OF_CLASSES series of models\n",
      "        \n",
      "        n_iter = self.n_estimators\n",
      "        \n",
      "        # Init model series\n",
      "        model_series = deque(maxlen = n_iter)            \n",
      "            \n",
      "        # Initial models\n",
      "        curr_models = [ InitModel() for i in range(NUM_OF_CLASSES) ]          \n",
      "        \n",
      "        dY = Y.astype(float)\n",
      "        dYT = dY.T\n",
      "        \n",
      "        for i in range(n_iter):\n",
      "            # Add models to series\n",
      "            model_series.append(curr_models)  \n",
      "            \n",
      "            # Fit models \n",
      "            for j in range(NUM_OF_CLASSES):\n",
      "                curr_models[j].fit(X, dY[:,j])\n",
      "                \n",
      "            # Predict models\n",
      "            # Output: 2D, Predicted is TRANSPOSED\n",
      "            PredictedT = np.array([curr_models[j].predict(X) for j in range(NUM_OF_CLASSES)])\n",
      "            \n",
      "            # Softmax\n",
      "            PredictedT = self.softmax(PredictedT, 0)\n",
      "            \n",
      "            # Calculate negative gradients \n",
      "            \n",
      "            dYT = dYT - self.l_rate * PredictedT\n",
      "            dY = dYT.T\n",
      "            \n",
      "            curr_models = [ copy.copy(self.learner) for i in range(NUM_OF_CLASSES) ]  # WARNING# WARNING\n",
      "            \n",
      "            #alpha[i] = 1  # learning rate; smaller alpha needs more classifiers\n",
      "                          # but predicts better\n",
      "\n",
      "        self.model_series = model_series \n",
      "            \n",
      "    \n",
      "    def fit(self, X, Y):\n",
      "        self.fit_all_classes(X, Y)\n",
      "\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
      "        #for models in models_per_class:\n",
      "        model_series = copy.copy(self.model_series)\n",
      "        predictedT = np.zeros((X.shape[0], NUM_OF_CLASSES)).T\n",
      "        predictedT = predictedT.astype(float)\n",
      "        \n",
      "        while len( model_series ) > 0:\n",
      "            models = model_series.popleft()\n",
      "            for i in range(NUM_OF_CLASSES):\n",
      "                #print(models[i].predict(X))\n",
      "                predictedT[i] += self.l_rate *  models[i].predict(X)   # This is all transposed\n",
      "        return np.array([self.softmax(p, 0) for p in predictedT.T])\n",
      "        #return  predictedT.T\n",
      "    \n",
      "class GradBoostModel():\n",
      "    \"\"\"Classifier for gradient boosting.\"\"\"\n",
      "    def __init__(self, models_per_each_class, l_rate = 0.1):\n",
      "        self.models_per_each_class = models_per_each_class\n",
      "        self.l_rate = l_rate\n",
      "        \n",
      "    def predict_class(self, X, models):\n",
      "        predict = 0\n",
      "        for model in models:\n",
      "            predict += self.l_rate * model.predict(X)\n",
      "        return predict\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
      "        #for models in models_per_class:\n",
      "        return np.array([ self.predict_class(X, models) for models in self.models_per_each_class]).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test fit_one_models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 20\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeClassifier(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=7)\n",
      "models_one_class = boost.fit_one_class(X, Y[:, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'GradBoostLearner' object has no attribute 'fit_one_class'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-53-ce05f3d5631e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradBoostLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodels_one_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'GradBoostLearner' object has no attribute 'fit_one_class'"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number should be the same as number of estimators\n",
      "len(models_one_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "7"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test fit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 20\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeRegressor(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=100)\n",
      "boost.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "matrix([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
        "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
        "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
        "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
        "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boost.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 175,
       "text": [
        "array([[  6.75345114e-04,   9.94410014e-01,   9.45649381e-04,\n",
        "          6.27081560e-04,   6.75345114e-04,   6.55976228e-04,\n",
        "          6.71362635e-04,   6.63881268e-04,   6.75345114e-04],\n",
        "       [  1.62238754e-03,   2.93106823e-03,   9.85563663e-01,\n",
        "          1.85379886e-03,   1.62238754e-03,   1.46099975e-03,\n",
        "          1.62906567e-03,   1.69424157e-03,   1.62238754e-03],\n",
        "       [  4.12354378e-04,   2.35177571e-04,   9.96689952e-01,\n",
        "          5.56876280e-04,   4.12354378e-04,   4.40859542e-04,\n",
        "          4.14224294e-04,   4.25846949e-04,   4.12354378e-04],\n",
        "       [  4.42667454e-04,   5.24076831e-04,   9.07896385e-04,\n",
        "          3.31460394e-04,   4.42667454e-04,   9.96059264e-01,\n",
        "          4.44493342e-04,   4.04806387e-04,   4.42667454e-04],\n",
        "       [  4.63217237e-04,   4.94804352e-04,   3.32364758e-04,\n",
        "          5.77395966e-04,   4.63217237e-04,   9.96295836e-01,\n",
        "          4.63674242e-04,   4.46272622e-04,   4.63217237e-04],\n",
        "       [  4.55126598e-04,   6.22758837e-04,   4.18312995e-04,\n",
        "          5.35982159e-04,   4.55126598e-04,   9.96166663e-01,\n",
        "          4.52898903e-04,   4.38004373e-04,   4.55126598e-04],\n",
        "       [  7.34896324e-04,   9.00992300e-04,   9.94055578e-01,\n",
        "          6.08412850e-04,   7.34896324e-04,   7.45503207e-04,\n",
        "          7.33497920e-04,   7.51327019e-04,   7.34896324e-04],\n",
        "       [  4.57201904e-04,   6.17814620e-04,   5.50800479e-04,\n",
        "          2.85196548e-04,   4.57201904e-04,   5.03739068e-04,\n",
        "          4.56747682e-04,   9.96214096e-01,   4.57201904e-04],\n",
        "       [  8.41671605e-04,   1.42117753e-03,   9.92764406e-01,\n",
        "          7.99398481e-04,   8.41671605e-04,   8.18281976e-04,\n",
        "          8.44755740e-04,   8.26965113e-04,   8.41671605e-04],\n",
        "       [  8.90469998e-04,   9.91978058e-01,   1.30494256e-03,\n",
        "          1.28814710e-03,   8.90469998e-04,   8.81455263e-04,\n",
        "          8.92288216e-04,   9.83698484e-04,   8.90469998e-04],\n",
        "       [  4.22220256e-04,   5.64121792e-04,   4.71863311e-04,\n",
        "          4.47433986e-04,   4.22220256e-04,   3.84205983e-04,\n",
        "          4.22318958e-04,   9.96443395e-01,   4.22220256e-04],\n",
        "       [  8.59283103e-04,   9.93164061e-01,   9.45962831e-04,\n",
        "          8.98248557e-04,   8.59283103e-04,   7.07265296e-04,\n",
        "          8.63017741e-04,   8.43595402e-04,   8.59283103e-04],\n",
        "       [  2.57726224e-04,   3.17649142e-04,   3.32407211e-04,\n",
        "          2.04386973e-04,   2.57726224e-04,   3.05571981e-04,\n",
        "          9.97748975e-01,   3.17831261e-04,   2.57726224e-04],\n",
        "       [  4.18520407e-04,   3.91637072e-04,   5.46133431e-04,\n",
        "          4.16161295e-04,   4.18520407e-04,   9.96558533e-01,\n",
        "          4.14891027e-04,   4.17083020e-04,   4.18520407e-04],\n",
        "       [  6.72406306e-04,   9.93785497e-01,   9.11817402e-04,\n",
        "          1.26625191e-03,   6.72406306e-04,   6.65599154e-04,\n",
        "          6.73779267e-04,   6.79836126e-04,   6.72406306e-04],\n",
        "       [  7.31763129e-04,   1.15677733e-03,   9.45090393e-04,\n",
        "          9.93505382e-01,   7.31763129e-04,   7.24355074e-04,\n",
        "          7.33257289e-04,   7.39848819e-04,   7.31763129e-04],\n",
        "       [  4.30056900e-04,   5.55483225e-04,   5.69777806e-04,\n",
        "          3.39029743e-04,   4.30056900e-04,   4.07992300e-04,\n",
        "          4.29361053e-04,   9.96408185e-01,   4.30056900e-04],\n",
        "       [  1.16699273e-03,   9.89376282e-01,   1.66039410e-03,\n",
        "          1.96901187e-03,   1.16699273e-03,   1.15587693e-03,\n",
        "          1.17387304e-03,   1.16358340e-03,   1.16699273e-03],\n",
        "       [  9.84212685e-04,   1.67480047e-03,   1.47033923e-03,\n",
        "          9.90889950e-01,   9.84212685e-04,   1.00717966e-03,\n",
        "          9.88675826e-04,   1.01641693e-03,   9.84212685e-04],\n",
        "       [  3.64680427e-04,   3.83069185e-04,   2.57311191e-04,\n",
        "          5.51905737e-04,   3.64680427e-04,   9.96987890e-01,\n",
        "          3.66638328e-04,   3.59143998e-04,   3.64680427e-04]])"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boost.model_series."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train[:threshold] == classifier.predict(X_train[:threshold])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "matrix([[ True,  True,  True,  True,  True,  True,  True,  True, False],\n",
        "        [ True,  True,  True,  True, False,  True,  True,  True,  True],\n",
        "        [ True, False,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True, False,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True, False,  True]], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Cross Validating"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeClassifier(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=1000)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36.26 s                                     ### Vmesni rezultat ###:  2.53022011327\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36.61 s                                     ### Vmesni rezultat ###:  5.77933331227\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.86 s                                     ### Vmesni rezultat ###:  3.41340777199\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "3.9076537325102687"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeClassifier(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=1000)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.88 s                                     ### Vmesni rezultat ###:  3.22248536621\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.79 s                                     ### Vmesni rezultat ###:  5.7601926554\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.63 s                                     ### Vmesni rezultat ###:  5.5457272286\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "4.8428017500696683"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeClassifier(max_depth=3)\n",
      "boost = GradBoostLearner(learner, n_estimators=1000)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 93.47 s                                     ### Vmesni rezultat ###:  5.49171087981\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 90.41 s                                     ### Vmesni rezultat ###:  5.54694831785\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.69 s                                     ### Vmesni rezultat ###:  6.85420121667\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 196,
       "text": [
        "5.9642868047785198"
       ]
      }
     ],
     "prompt_number": 196
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Comparisson"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeClassifier(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=1000)\n",
      "my_cross_validation(X, Y[:, 0], boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.85 s                                     ### Vmesni rezultat ###:  0.932080922201\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.82 s                                     ### Vmesni rezultat ###:  1.03564546911\n",
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.96 s                                     ### Vmesni rezultat ###:  1.34836064004\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "1.1053623437852709"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1, max_depth=1, random_state=0)\n",
      "my_cross_validation(X, np.array(Y[:, 0]).ravel(), clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.4 s                                     ### Vmesni rezultat ###:  1.19099828346\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.38 s                                     ### Vmesni rezultat ###:  1.24278175572\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.38 s                                     ### Vmesni rezultat ###:  1.24464059081\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "1.2261402099956025"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 5000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeRegressor(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=200)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-183-38fcb0608184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradBoostLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmy_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-178-a04d1b27a0d1>\u001b[0m in \u001b[0;36mmy_cross_validation\u001b[1;34m(X, Y, model, k)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-178-a04d1b27a0d1>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(pred, real)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmy_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\metrics\\metrics.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;31m# Check if dimensions are consistent.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m     \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         raise ValueError(\"y_true and y_pred have different number of classes \"\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_arrays\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    281\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                     \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 43\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Whole data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 50000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeRegressor(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=100)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 121.46 s                                     ### Vmesni rezultat ###:  0.874196316694\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-193-85901076a268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradBoostLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmy_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-178-a04d1b27a0d1>\u001b[0m in \u001b[0;36mmy_cross_validation\u001b[1;34m(X, Y, model, k)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-172-7e76478221d2>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_all_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-172-7e76478221d2>\u001b[0m in \u001b[0;36mfit_all_classes\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;31m# Fit models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                 \u001b[0mcurr_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;31m# Predict models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Oddaja"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 50000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeRegressor(max_depth=1)\n",
      "boost = GradBoostLearner(learner, n_estimators=100)\n",
      "boost.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = boost.predict(X_test)\n",
      "def write_to_file(predicted, name):\n",
      "    answer = np.matrix(predicted.astype(str))\n",
      "    ids = np.matrix(range(1, answer.shape[0]+1))\n",
      "    answer = np.hstack((ids.T.astype(str), answer))\n",
      "    answer = np.vstack((np.array([\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]), answer))\n",
      "    answer = answer.tolist()\n",
      "    answer = \"\\n\".join( [\",\".join(line) for line in answer] )\n",
      "\n",
      "    fo = open(\"../results/\"+name+\".csv\", \"wt\")\n",
      "    fo.write(answer)\n",
      "    fo.close()\n",
      "write_to_file(predicted, boost.name+\"_1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}