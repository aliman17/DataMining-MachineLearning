{
 "metadata": {
  "name": "",
  "signature": "sha256:19a558e0df99275663fafb5fdb47b78e3288fc051263418442852616b7e65978"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn import cross_validation\n",
      "from collections import deque\n",
      "from sklearn import preprocessing\n",
      "from sklearn import linear_model\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "import copy\n",
      "import time\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUM_OF_CLASSES = 0\n",
      "def load_data1():\n",
      "    \"\"\"Load keggle\"\"\"\n",
      "    global NUM_OF_CLASSES\n",
      "    X_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "    X_test = np.loadtxt(open(\"../data/test.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "    \n",
      "    y_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "    y_train = np.array([int(c[-2])-1 for c in y_train])  # Parse classes from Class_1 into 1\n",
      "    return X_train, y_train, X_test\n",
      "\n",
      "def load_data2():\n",
      "    \"\"\"Load iris\"\"\"\n",
      "    iris = datasets.load_iris()\n",
      "    X_train = iris.data\n",
      "    y_train = iris.target.T\n",
      "    return X_train, y_train, None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = 1\n",
      "if data == 1:\n",
      "    X_train, Y_train, X_test = load_data1()\n",
      "else:\n",
      "    X_train, Y_train, X_test = load_data2()\n",
      "NUM_OF_CLASSES = len( np.unique(Y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preprocesse Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shuffle(X, Y):\n",
      "    ind = np.array(list(range(X.shape[0])))\n",
      "    np.random.shuffle(ind)\n",
      "    X = np.array( [ X[i] for i in ind] )\n",
      "    Y = np.array( [ Y[i] for i in ind] )\n",
      "    return X, Y \n",
      "X_train, Y_train = shuffle(X_train, Y_train)\n",
      "std = preprocessing.StandardScaler()\n",
      "X_train = std.fit_transform(X_train)\n",
      "X_test = std.transform(X_test)\n",
      "X_train = np.matrix(X_train)\n",
      "X_test = np.matrix(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binaryClassRepresentation(Y):\n",
      "    \"\"\" Class 1 write as 1,0,0,0,0,0,0,0,0, class 2 write as 0,1,0,0,0,0,0,0,0, ... \"\"\"\n",
      "    I = np.identity(NUM_OF_CLASSES)\n",
      "    Y = np.array( [ I[y] for y in Y])\n",
      "    return Y\n",
      "Y_train = binaryClassRepresentation(Y_train)\n",
      "Y_train = np.matrix(Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate(pred, real):\n",
      "    return metrics.log_loss(real, pred)\n",
      "\n",
      "\n",
      "def my_cross_validation(X, Y, model, k=3):\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(Y), n_folds=k, shuffle=False)\n",
      "    for train_index, test_index in kf:\n",
      "        print(\"New fold\")\n",
      "        start = time.time()  \n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
      "        \n",
      "        model.fit(X_train, Y_train)\n",
      "        predicted = model.predict(X_test)\n",
      "        # Evaluate\n",
      "        score = evaluate(predicted, Y_test)\n",
      "         \n",
      "        end = time.time()\n",
      "        \n",
      "        print(\"        Time:\", round(end - start, 2), \"s                                     ### Vmesni rezultat ###: \",  score)\n",
      "        sys.stdout.flush()\n",
      "        S.append( score )\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Mean Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MeanModel():\n",
      "    def __init__(self):\n",
      "        pass\n",
      "        \n",
      "    def fit(self, X, Y):\n",
      "        self.Y = Y\n",
      "        \n",
      "    def predict(self, X):\n",
      "        if len(X.shape) == 1:\n",
      "            return np.mean(self.Y, axis=0)\n",
      "        else:\n",
      "            return np.array([np.array(np.mean(self.Y, axis=0))[0]] * X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 5\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "init = MeanModel(Y)\n",
      "\n",
      "init.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([[ 0. ,  0.4,  0. ,  0. ,  0.2,  0.2,  0. ,  0. ,  0.2],\n",
        "       [ 0. ,  0.4,  0. ,  0. ,  0.2,  0.2,  0. ,  0. ,  0.2],\n",
        "       [ 0. ,  0.4,  0. ,  0. ,  0.2,  0.2,  0. ,  0. ,  0.2],\n",
        "       [ 0. ,  0.4,  0. ,  0. ,  0.2,  0.2,  0. ,  0. ,  0.2],\n",
        "       [ 0. ,  0.4,  0. ,  0. ,  0.2,  0.2,  0. ,  0. ,  0.2]])"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Weak Learner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WeakLearner():\n",
      "    \"\"\"Weak learners generator class\"\"\"\n",
      "    def __init__(self, learner=\"decision_tree\", max_depth=1):\n",
      "        learners = {\"decision_tree\": tree.DecisionTreeRegressor,\n",
      "                    \"lr\": linear_model.LinearRegression,\n",
      "                    \"ridge\": linear_model.Ridge}\n",
      "        self.learner = learner\n",
      "        self.learner_func = learners[learner]\n",
      "        self.max_depth = max_depth\n",
      "    \n",
      "    def fit(self, X, Y):\n",
      "        \"\"\"Each fit creates new learner, fits it, and returns it.\"\"\" \n",
      "        if self.learner == \"decision_tree\":\n",
      "            learner = self.learner_func(max_depth=self.max_depth)\n",
      "        else:\n",
      "            learner = self.learner_func()\n",
      "        learner.fit(X, Y)\n",
      "        return learner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GradBoostLearner():\n",
      "    \"\"\"Gradient Boosting for Regression.\"\"\"\n",
      "\n",
      "    def __init__(self, weak_learner = \"decision_tree\", max_depth=1, n_estimators=10, epsilon=1e-5, l_rate = 1, loss=\"squared\"):\n",
      "        \n",
      "        self.new_weak_learner = WeakLearner(weak_learner, max_depth)  # Initialize new weak learner generator\n",
      "        self.n_estimators = n_estimators\n",
      "        self.epsilon = epsilon\n",
      "        self.l_rate = l_rate\n",
      "        losses = {\"huber\": self.grad_huber_loss, \n",
      "                  \"squared\": self.grad_squared_loss, \n",
      "                  \"abs\": self.grad_abs_loss,\n",
      "                  \"log_loss\": self.log_loss}\n",
      "        self.loss = losses[loss]\n",
      "        self.models = None\n",
      "        \n",
      "        self.name = \"gb_est\" + str(self.n_estimators) + \"_Lrate\"+str(l_rate) + \"_\" + loss\n",
      "\n",
      "    \n",
      "    def log_loss(self, y, f):\n",
      "        \"\"\"Negative gradient for log loss\n",
      "        WARNING: There are problems with denominators!!!\"\"\"\n",
      "        return - (y - f) / (f * (1 - f))\n",
      "    \n",
      "    def grad_squared_loss(self, y, f):\n",
      "        \"\"\"Negative gradiant for squared loss.\"\"\"\n",
      "        return y - f\n",
      "    \n",
      "    def grad_abs_loss(self, y, f):\n",
      "        \"\"\"Negative gradient for absolute loss.\"\"\"\n",
      "        return np.sign(y - f)\n",
      "    \n",
      "    def grad_huber_loss(self, y, f, delta=0.5):\n",
      "        \"\"\"Negative gradient for Huber loss.\"\"\"\n",
      "        r0 = y - f\n",
      "        r1 = delta * np.sign(r0)\n",
      "        return np.vstack((r0, r1)).T[np.arange(y.shape[0]), (np.abs(r0)>delta).astype(int)]\n",
      "    \n",
      "   \n",
      "    def softmax(self, X, axis = 1):\n",
      "        # Description: Function apply softmax on a vector\n",
      "        #\n",
      "        # Input:     \n",
      "        #\n",
      "        # Output: new array of corrected input\n",
      "        \n",
      "        newX = np.exp( X )\n",
      "        SumX = np.sum( newX, axis = axis )   # sum rows, because these are gonna be denumerators\n",
      "        newX = newX / SumX \n",
      "        return newX\n",
      "\n",
      "    \n",
      "    def fit_all_classes(self, X, Y):\n",
      "        # Description: Function performs gradient boosting for ALL classes\n",
      "        #\n",
      "        # Input:       X     matrix of samples\n",
      "        #              Y     MATRIX of a classes identification\n",
      "        #\n",
      "        # Output:      List of fitted models that are used for classification.\n",
      "        \n",
      "        \n",
      "        # Prepare list of queues which are intended for NUM_OF_CLASSES series of models\n",
      "        NUM_OF_CLASSES = Y.shape[1]\n",
      "        N_ITER = self.n_estimators\n",
      "        \n",
      "        # Storage for models\n",
      "        storage_models = [None] * (N_ITER)\n",
      "        \n",
      "        # Initialize starting value\n",
      "        Predicted_sum_T = np.array([np.array(np.mean(Y, axis=0))[0]] * X.shape[0]).T\n",
      "        \n",
      "        Y_T = Y.astype(float).T\n",
      "        \n",
      "        for i in range(N_ITER):     \n",
      "            # Calculate P for each model\n",
      "            P_T = self.softmax(Predicted_sum_T, 0)      # Use softmax on predicted data\n",
      "            \n",
      "            Residual_T = self.loss(Y_T, P_T)            # WARNING not working for Huber!!!\n",
      "            #Residual_T = Y_T - P_T                     # Compute residuals\n",
      "            Residual = Residual_T.T                     # Create a transposed version\n",
      "            #print(Residual_T)\n",
      "            \n",
      "            fitted_weak_learners = [ self.new_weak_learner.fit(X, Residual[:, j]) for j in range(NUM_OF_CLASSES) ]\n",
      "            new_predicted_values = [ weak_learner.predict(X) for weak_learner in fitted_weak_learners]\n",
      "            if len(new_predicted_values[0].shape) == 2:\n",
      "                new_predicted_values = [ values.T[0] for values in new_predicted_values]\n",
      "            new_predicted_values = np.array(new_predicted_values)\n",
      "            \n",
      "            #print(new_predicted_values)\n",
      "            #break\n",
      "            Predicted_sum_T = Predicted_sum_T + self.l_rate * new_predicted_values   # WARNING LEARNING RATE\n",
      "            storage_models[i] = fitted_weak_learners\n",
      "\n",
      "        self.storage_models = storage_models \n",
      "        return storage_models\n",
      "    \n",
      "    \n",
      "    def grad_check(self, X, Y):\n",
      "        # Description: Function performs gradient boosting for ALL classes\n",
      "        #\n",
      "        # Input:       X     matrix of samples\n",
      "        #              Y     MATRIX of a classes identification\n",
      "        #\n",
      "        # Output:      List of fitted models that are used for classification.\n",
      "        \n",
      "        \n",
      "        # Description: Function performs gradient boosting for ALL classes\n",
      "        #\n",
      "        # Input:       X     matrix of samples\n",
      "        #              Y     MATRIX of a classes identification\n",
      "        #\n",
      "        # Output:      List of fitted models that are used for classification.\n",
      "        \n",
      "        \n",
      "        # Prepare list of queues which are intended for NUM_OF_CLASSES series of models\n",
      "        NUM_OF_CLASSES = Y.shape[1]\n",
      "        N_ITER = self.n_estimators\n",
      "        \n",
      "        # Storage for models\n",
      "        storage_models = [None] * (N_ITER)\n",
      "        \n",
      "        # Initialize starting value\n",
      "        Predicted_sum_T = np.array([np.array(np.mean(Y, axis=0))[0]] * X.shape[0]).T\n",
      "        \n",
      "        Y_T = Y.astype(float).T\n",
      "        \n",
      "        for i in range(N_ITER):     \n",
      "            # Calculate P for each model\n",
      "            P_T = self.softmax(Predicted_sum_T, 0)      # Use softmax on predicted data\n",
      "            Residual_T = Y_T - P_T   # Compute residuals\n",
      "            Residual = Residual_T.T                 # Create a transposed version\n",
      "            \n",
      "            fitted_weak_learners = [ self.new_weak_learner.fit(X, Residual[:, j]) for j in range(NUM_OF_CLASSES) ]\n",
      "            new_predicted_values = [ weak_learner.predict(X) for weak_learner in fitted_weak_learners]\n",
      "            if len(new_predicted_values[0].shape) == 2:\n",
      "                new_predicted_values = [ values.T[0] for values in new_predicted_values]\n",
      "            new_predicted_values = np.array(new_predicted_values)\n",
      "            \n",
      "            #print(new_predicted_values)\n",
      "            #break\n",
      "            Predicted_sum_T = Predicted_sum_T + self.l_rate * new_predicted_values   # WARNING LEARNING RATE\n",
      "            storage_models[i] = fitted_weak_learners\n",
      "\n",
      "        self.storage_models = storage_models \n",
      "        return storage_models\n",
      "            \n",
      "    \n",
      "    def fit(self, X, Y):\n",
      "        self.fit_all_classes(X, Y)\n",
      "\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
      "        #for models in models_per_class:\n",
      "        predictedT = np.zeros((X.shape[0], NUM_OF_CLASSES)).T\n",
      "        predictedT = predictedT.astype(float)\n",
      "        \n",
      "        for models in self.storage_models:\n",
      "            for i in range(NUM_OF_CLASSES):\n",
      "                pred =  models[i].predict(X)\n",
      "                if len(pred.shape) == 2:\n",
      "                    pred = pred.T[0]\n",
      "                predictedT[i] += self.l_rate *  pred   # This is all transposed\n",
      "        return np.array([self.softmax(p, 0) for p in predictedT.T])\n",
      "        #return  predictedT.T\n",
      "    \n",
      "class GradBoostModel():\n",
      "    \"\"\"Classifier for gradient boosting.\"\"\"\n",
      "    def __init__(self, models_per_each_class, l_rate = 0.1):\n",
      "        self.models_per_each_class = models_per_each_class\n",
      "        self.l_rate = l_rate\n",
      "        \n",
      "    def predict_class(self, X, models):\n",
      "        predict = 0\n",
      "        for model in models:\n",
      "            predict += self.l_rate * model.predict(X)\n",
      "        return predict\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
      "        #for models in models_per_class:\n",
      "        return np.array([ self.predict_class(X, models) for models in self.models_per_each_class]).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check gradient"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grad_approx(J, x, e=1e-5):\n",
      "        return (J(x+e) - J(x-e))/(2*e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.array([1,2,2,3,1,21])\n",
      "b = np.array([1.1,2.1,2.1,3.1,1.1,21.2])\n",
      "grad_approx(lambda x: metrics.log_loss(a, x), b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "y_true and y_pred have different number of classes 4, 2",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-152-b32bb2d3e0b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrad_approx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-151-1a0a0320553c>\u001b[0m in \u001b[0;36mgrad_approx\u001b[1;34m(J, x, e)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad_approx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-152-b32bb2d3e0b4>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrad_approx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\metrics\\metrics.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         raise ValueError(\"y_true and y_pred have different number of classes \"\n\u001b[1;32m-> 1123\u001b[1;33m                          \"%d, %d\" % (T.shape[1], Y.shape[1]))\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;31m# Renormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of classes 4, 2"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test fit all classes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 4\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=8)\n",
      "boost.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number should be the same as number of estimators\n",
      "len(models_one_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test fit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 20\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=8)\n",
      "boost.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train[:threshold] == (boost.predict(X_train[:threshold])>0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "matrix([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
        "        [ True,  True,  True,  True,  True,  True,  True,  True,  True]], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check number of estimators"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "100"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=100)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.28 s                                     ### Vmesni rezultat ###:  0.85201489287\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.4 s                                     ### Vmesni rezultat ###:  0.857319054739\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.57 s                                     ### Vmesni rezultat ###:  0.904501017417\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "0.8712783216754324"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "200"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=200)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.68 s                                     ### Vmesni rezultat ###:  0.795661496083\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.4 s                                     ### Vmesni rezultat ###:  0.795709182852\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.87 s                                     ### Vmesni rezultat ###:  0.861153457978\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "0.81750804563754409"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "300"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=300)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.17 s                                     ### Vmesni rezultat ###:  0.776641559237\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.97 s                                     ### Vmesni rezultat ###:  0.767727422965\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.12 s                                     ### Vmesni rezultat ###:  0.844622553593\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "0.79633051193166693"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "400"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=400)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14.8 s                                     ### Vmesni rezultat ###:  0.769403624417\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13.64 s                                     ### Vmesni rezultat ###:  0.751354579327\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13.42 s                                     ### Vmesni rezultat ###:  0.835661904133\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "0.78547336929212663"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "500"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=500)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18.27 s                                     ### Vmesni rezultat ###:  0.766252904952\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18.22 s                                     ### Vmesni rezultat ###:  0.742777745935\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16.84 s                                     ### Vmesni rezultat ###:  0.834366089281\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "0.78113224672263593"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "600"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=600)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23.13 s                                     ### Vmesni rezultat ###:  0.768942709021\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19.23 s                                     ### Vmesni rezultat ###:  0.740282570979\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19.15 s                                     ### Vmesni rezultat ###:  0.83492396047\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 93,
       "text": [
        "0.78138308015663427"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "CONCLUSION: It seems that 400 or 500 iterations is enought. Higher numbers don't show improvement. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check depth of the trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", max_depth=2,n_estimators=400)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24.21 s                                     ### Vmesni rezultat ###:  0.773325542582\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24.98 s                                     ### Vmesni rezultat ###:  0.74350877726\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24.25 s                                     ### Vmesni rezultat ###:  0.896920571114\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "0.80458496365176468"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", max_depth=3,n_estimators=400)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.34 s                                     ### Vmesni rezultat ###:  0.809989336262\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.95 s                                     ### Vmesni rezultat ###:  0.824662217812\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.15 s                                     ### Vmesni rezultat ###:  0.966816913349\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "0.86715615580799488"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "CONCLUSION: Results get worse with deeper trees."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Other weak learners"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"ridge\",n_estimators=400)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.19 s                                     ### Vmesni rezultat ###:  1.01373373304\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.32 s                                     ### Vmesni rezultat ###:  1.04594987488\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89.71 s                                     ### Vmesni rezultat ###:  0.998074637915\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "1.0192527486101843"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learning rate"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "200 iterations, 0.25 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=200, l_rate=0.25)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.69 s                                     ### Vmesni rezultat ###:  0.939019018077\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.55 s                                     ### Vmesni rezultat ###:  0.939141679038\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.68 s                                     ### Vmesni rezultat ###:  0.979857980658\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "0.9526728925910235"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "500 iterations, 0.25 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=500, l_rate=0.25)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16.46 s                                     ### Vmesni rezultat ###:  0.831717278393\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16.59 s                                     ### Vmesni rezultat ###:  0.834421141075\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16.9 s                                     ### Vmesni rezultat ###:  0.890592733458\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "0.85224371764178841"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "1000 iterations, 0.25 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=1000, l_rate=0.25)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32.97 s                                     ### Vmesni rezultat ###:  0.78420248453\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35.53 s                                     ### Vmesni rezultat ###:  0.775599010158\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36.15 s                                     ### Vmesni rezultat ###:  0.852925196042\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "0.80424223024322361"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "2000 iterations, 0.25 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=2000, l_rate=0.25)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71.76 s                                     ### Vmesni rezultat ###:  0.767866063131\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 69.09 s                                     ### Vmesni rezultat ###:  0.739602448015\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67.82 s                                     ### Vmesni rezultat ###:  0.833943640667\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 168,
       "text": [
        "0.78047071727091533"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "3000 iteration, 0.25 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=3000, l_rate=0.25)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.85 s                                     ### Vmesni rezultat ###:  0.770636229752\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.29 s                                     ### Vmesni rezultat ###:  0.735778168803\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.44 s                                     ### Vmesni rezultat ###:  0.838035099226\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 169,
       "text": [
        "0.78148316592706879"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "CONCLUSION: 0.25 stops decreasing at 2000 iteration."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "400 iterations, 0.125 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=400, l_rate=0.125)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13.78 s                                     ### Vmesni rezultat ###:  0.940282776204\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12.88 s                                     ### Vmesni rezultat ###:  0.939881636499\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13.5 s                                     ### Vmesni rezultat ###:  0.980394067144\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "0.95351949328212016"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "1000 iteraitons, 0.125 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=1000, l_rate=0.125)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.38 s                                     ### Vmesni rezultat ###:  0.832784016649\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32.81 s                                     ### Vmesni rezultat ###:  0.834872786603\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34.95 s                                     ### Vmesni rezultat ###:  0.890600350419\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "0.85275238455683156"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "2000 iteration, 0.125 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=2000, l_rate=0.125)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.01 s                                     ### Vmesni rezultat ###:  0.783919683872\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 75.68 s                                     ### Vmesni rezultat ###:  0.776775192198\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.37 s                                     ### Vmesni rezultat ###:  0.852417198253\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "0.80437069144121243"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "3000 iterations, 0.125 learning rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=3000, l_rate=0.125)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.0 s                                     ### Vmesni rezultat ###:  0.770889099516\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.71 s                                     ### Vmesni rezultat ###:  0.751894376901\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 105.86 s                                     ### Vmesni rezultat ###:  0.837541229413\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "0.7867749019436876"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=200, l_rate=0.25)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "CONCLUSION: Smaller learning rate gives better result but needs many more iterations. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Whole data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 50000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=300)\n",
      "my_cross_validation(X, Y, boost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n",
        "        Time:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 405.82 s                                     ### Vmesni rezultat ###:  0.705735410074\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New fold\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-96-0e4b916ea073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradBoostLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweak_learner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"decision_tree\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmy_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-6-a04d1b27a0d1>\u001b[0m in \u001b[0;36mmy_cross_validation\u001b[1;34m(X, Y, model, k)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-86-e5319676f3dd>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_all_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-86-e5319676f3dd>\u001b[0m in \u001b[0;36mfit_all_classes\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mResidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResidual_T\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m                 \u001b[1;31m# Create a transposed version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mfitted_weak_learners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_weak_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResidual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mnew_predicted_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mweak_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweak_learner\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfitted_weak_learners\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-86-e5319676f3dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mResidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResidual_T\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m                 \u001b[1;31m# Create a transposed version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mfitted_weak_learners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_weak_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResidual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mnew_predicted_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mweak_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweak_learner\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfitted_weak_learners\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-83-f1d3610bd4a0>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;34m\"\"\"Each fit creates new learner, fits it, and returns it.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "STACKING"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__author__ = 'Sushant'\n",
      "from sklearn.base import BaseEstimator, ClassifierMixin\n",
      "from scipy.optimize import minimize\n",
      "from sklearn.metrics import log_loss\n",
      "import numpy\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "\n",
      "\"\"\"\n",
      "Usage:\n",
      "\n",
      "estimators = []\n",
      "estimators.append(RandomForestClassifier(n_estimators = 100))\n",
      "estimators.append(GMM(n_components = 9))\n",
      "\n",
      "C_MC = MegaClassifier(estimators = estimators, xv_tries = 5)\n",
      "C_MC. fit(X_train, y_train)\n",
      "\n",
      "C_MC.predict_proba(X_test)\n",
      "\n",
      "Description:\n",
      "\n",
      "The MegaClassifier object automatically partitions training data in a \n",
      "stratified manner into 'xv_tries' number of folds (default 4), trains\n",
      "all models in 'estimators' with the stratified training sets and records\n",
      "their output on the stratified validation set.\n",
      "\n",
      "During optimization it selects weights that result in minimization of \n",
      "averaged log-loss across all the validation sets.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "class StratifiedSplit(object):\n",
      "    @staticmethod\n",
      "    def train_test_split( X, y, test_size = 0.2):\n",
      "        res = StratifiedShuffleSplit(y, n_iter=1, test_size=test_size)\n",
      "        for ind_train, ind_test in res:\n",
      "            X_train = []\n",
      "            y_train = []\n",
      "            X_test = []\n",
      "            y_test = []\n",
      "            for ind in ind_train:\n",
      "                X_train.append(X[ind])\n",
      "                y_train.append(y[ind])\n",
      "\n",
      "            for ind in ind_test:\n",
      "                X_test.append(X[ind])\n",
      "                y_test.append(y[ind])\n",
      "\n",
      "            return X_train, X_test, y_train, y_test\n",
      "\n",
      "\n",
      "class MegaClassifier(BaseEstimator, ClassifierMixin):\n",
      "    def __init__(self, estimators, xv_tries=4, test_size=0.2):\n",
      "        self.estimators = estimators\n",
      "        self.xv_tries = xv_tries\n",
      "        self.test_size = test_size\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        self.X_trains = []\n",
      "        self.y_trains = []\n",
      "        self.X_valids = []\n",
      "        self.y_valids = []\n",
      "        for i in range(self.xv_tries):\n",
      "            Xt, Xv, yt, yv = StratifiedSplit.train_test_split(X, y, test_size=self.test_size)\n",
      "            self.X_trains.append(Xt)\n",
      "            self.X_valids.append(Xv)\n",
      "            self.y_trains.append(yt)\n",
      "            self.y_valids.append(yv)\n",
      "\n",
      "        # train the classifiers\n",
      "        self.all_xv_predictions = []\n",
      "\n",
      "        for ind, Xt in enumerate(self.X_trains):\n",
      "            cur_xv_predictions = []\n",
      "            for estimator in self.estimators:\n",
      "                #new_est = copy.deepcopy(estimator)\n",
      "                #new_est.fit(Xt, self.y_trains[ind])\n",
      "                estimator.fit(Xt, self.y_trains[ind])\n",
      "                cur_xv_predictions.append(estimator.predict_proba(self.X_valids[ind]))\n",
      "            self.all_xv_predictions.append(cur_xv_predictions)\n",
      "\n",
      "        num_estimators = len(self.estimators)\n",
      "        initial_weights = [1.0 / float(num_estimators) for i in xrange(num_estimators)]\n",
      "\n",
      "        print (\"Optimizing....\")\n",
      "        bounds = [(0, 1) for i in xrange(num_estimators)]\n",
      "        constraints = {'type': 'eq', 'fun': lambda w: 1 - sum(w)}\n",
      "        res = minimize(self.__find_best_blending_weights, initial_weights, bounds=bounds, constraints=constraints)\n",
      "        self.final_weights = res.x\n",
      "        print (\"Optimization finished...\")\n",
      "\n",
      "        print (\"Weights:\")\n",
      "        print (self.final_weights)\n",
      "\n",
      "        for estimator in self.estimators:\n",
      "            estimator.fit(X, y)\n",
      "\n",
      "\n",
      "    def __find_best_blending_weights(self, weights):\n",
      "        log_losses = []\n",
      "        for ind1, xv_predictions in enumerate(self.all_xv_predictions):\n",
      "            y_final_pred_prob = None\n",
      "            for ind, est_predictions in enumerate(xv_predictions):\n",
      "                if y_final_pred_prob is None:\n",
      "                    y_final_pred_prob = weights[ind] * est_predictions\n",
      "                else:\n",
      "                    y_final_pred_prob = numpy.add(y_final_pred_prob, (weights[ind] * est_predictions))\n",
      "            log_losses.append(log_loss(self.y_valids[ind1], y_final_pred_prob))\n",
      "\n",
      "        log_losses = numpy.array(log_losses)\n",
      "        return log_losses.mean()\n",
      "\n",
      "    def predict_proba(self, X):\n",
      "\n",
      "        y_final_pred_prob = None\n",
      "        for ind, estimator in enumerate(self.estimators):\n",
      "            y_pp_cur = estimator.predict_proba(X)\n",
      "            if y_final_pred_prob is None:\n",
      "                y_final_pred_prob = self.final_weights[ind] * y_pp_cur\n",
      "            else:\n",
      "                y_final_pred_prob = numpy.add(y_final_pred_prob, (self.final_weights[ind] * y_pp_cur))\n",
      "        return y_final_pred_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.neural_network import BernoulliRBM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 2000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "estimators = []\n",
      "estimators.append(RandomForestClassifier(n_estimators = 100))\n",
      "estimators.append(BernoulliRBM())\n",
      "\n",
      "C_MC = MegaClassifier(estimators = estimators, xv_tries = 3)\n",
      "C_MC. fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-177-97f4937a503f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mC_MC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMegaClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxv_tries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mC_MC\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-175-0c2834f4027d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_valids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxv_tries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedSplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_trains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_valids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-175-0c2834f4027d>\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(X, y, test_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mind_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_test\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_iter, test_size, train_size, indices, random_state, n_iterations)\u001b[0m\n\u001b[0;32m   1006\u001b[0m             n_iterations)\n\u001b[0;32m   1007\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m         \u001b[0mn_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mperm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mergesort'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'quicksort'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C_MC.predict_proba(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "ODDAJA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 50000\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "boost = GradBoostLearner(weak_learner=\"decision_tree\", n_estimators=2000, l_rate=0.25)\n",
      "boost.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = boost.predict(X_test)\n",
      "def write_to_file(predicted, name):\n",
      "    answer = np.matrix(predicted.astype(str))\n",
      "    ids = np.matrix(range(1, answer.shape[0]+1))\n",
      "    answer = np.hstack((ids.T.astype(str), answer))\n",
      "    answer = np.vstack((np.array([\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]), answer))\n",
      "    answer = answer.tolist()\n",
      "    answer = \"\\n\".join( [\",\".join(line) for line in answer] )\n",
      "\n",
      "    fo = open(\"../results/\"+name+\".csv\", \"wt\")\n",
      "    fo.write(answer)\n",
      "    fo.close()\n",
      "write_to_file(predicted, boost.name+\"_2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}