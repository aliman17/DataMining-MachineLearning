{
 "metadata": {
  "name": "",
  "signature": "sha256:c259c3b2562a2d55403c355e523067838349bfc59da4cfc709c50eb60f4377e8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "import Orange"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUM_OF_CLASSES = 0\n",
      "def load_data1():\n",
      "    \"\"\"Load keggle\"\"\"\n",
      "    global NUM_OF_CLASSES\n",
      "    X_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "    X_test = np.loadtxt(open(\"../data/test.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "    \n",
      "    y_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "    y_train = np.array([int(c[-2])-1 for c in y_train])  # Parse classes from Class_1 into 1\n",
      "    return X_train, y_train, X_test\n",
      "\n",
      "def load_data2():\n",
      "    \"\"\"Load iris\"\"\"\n",
      "    iris = datasets.load_iris()\n",
      "    X_train = iris.data\n",
      "    y_train = iris.target.T\n",
      "    return X_train, y_train, None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = 1\n",
      "if data == 1:\n",
      "    X_train, Y_train, X_test = load_data1()\n",
      "else:\n",
      "    X_train, Y_train, X_test = load_data2()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUM_OF_CLASSES = len( np.unique(Y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preprocesse Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shuffle(X, Y):\n",
      "    ind = np.array(list(range(X.shape[0])))\n",
      "    np.random.shuffle(ind)\n",
      "    X = np.array( [ X[i] for i in ind] )\n",
      "    Y = np.array( [ Y[i] for i in ind] )\n",
      "    return X, Y "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, Y_train = shuffle(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "std = preprocessing.StandardScaler()\n",
      "X_train = std.fit_transform(X_train)\n",
      "X_test = std.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.matrix(X_train)\n",
      "X_test = np.matrix(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binaryClassRepresentation(Y):\n",
      "    \"\"\" Class 1 write as 1,0,0,0,0,0,0,0,0, class 2 write as 0,1,0,0,0,0,0,0,0, ... \"\"\"\n",
      "    I = np.identity(NUM_OF_CLASSES)\n",
      "    Y = np.array( [ I[y] for y in Y])\n",
      "    return Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train = binaryClassRepresentation(Y_train)\n",
      "Y_train = np.matrix(Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GradBoostLearner():\n",
      "    \"\"\"Gradient Boosting for Regression.\"\"\"\n",
      "\n",
      "    def __init__(self, learner, n_estimators=10, epsilon=1e-5, loss=\"log_loss\"):\n",
      "        self.n_estimators = n_estimators\n",
      "        self.learner = learner  # base learner\n",
      "#        self.name = \"gb \" + self.learner.name + \" \" + loss\n",
      "        self.epsilon = epsilon\n",
      "        losses = {\"log_loss\": self.log_loss}\n",
      "        self.loss = losses[loss]\n",
      "\n",
      "    \n",
      "    def log_loss(self, real, pred):\n",
      "        \"\"\"Log loss\"\"\"\n",
      "        return metrics.log_loss(real, pred)\n",
      "    \n",
      "    \n",
      "    def fit_one_class(self, X, Y):\n",
      "        # Description: Function performs gradient boosting on one class\n",
      "        #\n",
      "        # Input:       X     matrix of samples\n",
      "        #              Y     matrix or vector of a class identification\n",
      "        #\n",
      "        # Output:      List of fitted models that are used for classification.\n",
      "        \n",
      "        # Prepare data for learning\n",
      "        dY = Y\n",
      "        \n",
      "        n_iter = self.n_estimators\n",
      "        models = [0] * n_iter\n",
      "        alpha = [0] * n_iter\n",
      "        for i in range(n_iter):\n",
      "            models[i] = self.learner()\n",
      "            alpha[i] = 1  # learning rate; smaller alpha needs more classifiers\n",
      "                          # but predicts better\n",
      "            dY = dY - alpha[i] * models[i].fit(X, dY)\n",
      "        return models\n",
      "            \n",
      "    \n",
      "    def fit(self, X, Y):\n",
      "        # Description: Function fits a model\n",
      "        #\n",
      "        # Input:       X     matrix of samples\n",
      "        #              Y     matix of classes; each column represents one class identification\n",
      "        # \n",
      "        # Output:      None\n",
      "        \n",
      "        # Start with constant mean predictor (suggestion from some sites)\n",
      "        # However, it doesn't work for us, because we have Y as a matrix\n",
      "        # with zeros and one number one. \n",
      "        \n",
      "        # First iterate through Y\n",
      "        models_per_class = []\n",
      "        for y_ in Y:\n",
      "            models = fit_one_class(X, y_)\n",
      "            models_per_class += [models]\n",
      "            \n",
      "        return \n",
      "    \n",
      "    \n",
      "    def fit_storage(self, data):\n",
      "        \"\"\"Fitter. Learns a set of models for gradient boosting.\"\"\"\n",
      "        ml = Orange.regression.MeanLearner()\n",
      "        model = ml(data)\n",
      "        y = data.Y\n",
      "        f = model(data)\n",
      "        res = self.loss(y, f)\n",
      "        models = [model]\n",
      "        \n",
      "        for i in range(self.n_estimators):\n",
      "            data = Orange.data.Table(data.X, res)\n",
      "            model = self.learner(data)\n",
      "            f += model(data)\n",
      "            res = self.loss(y, f)\n",
      "            models.append(model)\n",
      "        return GradBoostRModel(models)\n",
      "    \n",
      "class GradBoostModel():\n",
      "    \"\"\"Classifier for gradient boosting.\"\"\"\n",
      "    def __init__(self, models_per_class):\n",
      "        self.models_per_class = models_per_class\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
      "        #for models in models_per_class:\n",
      "            \n",
      "        return sum([m(X) for m in self.models])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Test fit_one_models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 10\n",
      "X = X_train[:threshold]\n",
      "Y = Y_train[:threshold]\n",
      "\n",
      "learner = tree.DecisionTreeClassifier(max_depth=1)\n",
      "boost = GradBoostLearner(learner)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'DecisionTreeClassifier' object has no attribute 'name'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-27-76ce5712496d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradBoostLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-24-1aa940155b4f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, learner, n_estimators, epsilon, loss)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner\u001b[0m  \u001b[1;31m# base learner\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gb \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"log_loss\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'name'"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}