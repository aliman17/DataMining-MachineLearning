{
 "metadata": {
  "name": "",
  "signature": "sha256:160eb7b874f1efd5e2ad893545d510eb233929f660bfdb47e2872a7c5d05d454"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# parser\n",
      "data = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "classes = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "# get class\n",
      "intClasses = []\n",
      "for c in classes:\n",
      "    intClasses += [int(c[-2])]\n",
      "intClasses = np.array(intClasses)\n",
      "data = np.hstack((data, np.matrix(intClasses).T))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logistic_function(z):\n",
      "    return 1 / (1 + np.exp(-z))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SoftmaxRegression():\n",
      "    def __init__(self):\n",
      "        pass\n",
      "\n",
      "    def l2_regularization(self, vector_):\n",
      "        return sum( vector_**2 )\n",
      "\n",
      "    def cost_function(self, theta_):\n",
      "        \"\"\"Error function\"\"\"\n",
      "        e = 1e-15   # For correction of -inf\n",
      "        y_ = self.y_train\n",
      "        X = self.X_train\n",
      "        \n",
      "        m = len(y_)\n",
      "        s = 0\n",
      "        for i in range(m):\n",
      "            g = logistic_function( np.dot( theta_, X[i, :] ) )\n",
      "            s += np.maximum(np.log(g), e)  + (1 - self.y_train[i]) * np.maximum(np.log(1-g), e) \n",
      "            #s += y_[i] * math.log(g) + (1 - y_[i]) * math.log(1 - g)\n",
      "        J = -(1/m) * s + self.alpha/(2*m)  * self.l2_regularization(theta_) \n",
      "        # Warning: Using minus. We can do max, but we need min.\n",
      "        return J\n",
      "\n",
      "    def grad_cost_function(self, theta_):\n",
      "        \"\"\"Gradient of error function\"\"\"\n",
      "        e = 1e-15\n",
      "        y_ = self.y_train\n",
      "        X = self.X_train\n",
      "        m = len(y_)\n",
      "        # s is a vector\\n\",\n",
      "        s_ = np.zeros_like(theta_) \n",
      "        for i in range(m):\n",
      "            g = logistic_function( np.dot( theta_, X[i, :]  ) )\n",
      "            s_ += g - y_[i] * X[i, :]\n",
      "        # Add regularization\n",
      "        s_ = -1/m * s_ + self.alpha/m * theta_\n",
      "        return s_\n",
      "    \n",
      "    def get_params(self, deep=True):\n",
      "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
      "        return {}\n",
      "\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)\n",
      "        return self\n",
      "    \n",
      "    def fit(self, X_train=None, y_train=None):\n",
      "        self.X_train = X_train\n",
      "        self.y_train = y_train\n",
      "        self.alpha = 0.1\n",
      "        \n",
      "        theta_ = np.ones(self.X_train.shape[1])  # Starting point\n",
      "        self.theta = fmin_bfgs(self.cost_function, theta_, fprime=self.grad_cost_function)  # , disp=False\n",
      "        return self.theta\n",
      "    \n",
      "        \n",
      "    def predict(self, X):\n",
      "        \"\"\"Predict 1 or 0 for a given vector x_\"\"\"\n",
      "        result = [logistic_function(np.dot(self.theta, x_)) for x_ in X]\n",
      "        return result\n",
      "    \n",
      "    def decision_function(self, X):\n",
      "        \"\"\"Predict 1 or 0 for a given vector x_\"\"\"\n",
      "        result = [logistic_function(np.dot(self.theta, x_)) for x_ in X]\n",
      "        return result\n",
      "    #result**y * (1 - result) ** (1 - y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}