{
 "metadata": {
  "name": "",
  "signature": "sha256:375c223e1d350120310b3a47ecbc0b1f8a5ca6168b3752241e16ae710139e071"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usefull links\n",
      "- http://blog.smellthedata.com/2009/06/python-logistic-regression-with-l2.html\n",
      "- http://scikit-learn.org/stable/modules/multiclass.html\n",
      "- http://scikit-learn.org/stable/developers/#get-params-and-set-params"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "import scipy as sp\n",
      "from scipy.optimize.optimize import fmin_bfgs\n",
      "from sklearn.base import BaseEstimator, ClassifierMixin\n",
      "from sklearn.preprocessing import normalize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "classes = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "# get class\n",
      "intClasses = []\n",
      "for c in classes:\n",
      "    intClasses += [int(c[-2])]\n",
      "y = np.array(intClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def numerical_grad(f, params, epsilon):\n",
      "    \"\"\"Method of finite differences, sanity check to see if our Jgrad is implemented correctly\"\"\"\n",
      "    num_grad = np.zeros_like(params)\n",
      "    perturb = np.zeros_like(params)\n",
      "    for i in range(params.size):\n",
      "        perturb[i] = epsilon\n",
      "        j1 = f(params + perturb)\n",
      "        j2 = f(params - perturb)\n",
      "        num_grad[i] = (j1 - j2) / (2. * epsilon)\n",
      "        perturb[i] = 0\n",
      "    return num_grad\n",
      "\n",
      "# TODO Gradient ne dela\n",
      "def check_grad(LR, theta_):\n",
      "    f = lambda theta: LR.cost_function(theta)\n",
      "    ag = LR.grad_cost_function(theta_)\n",
      "    ng = numerical_grad(f, theta_, 1e-4)\n",
      "    return np.sum((ag - ng)**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logistic_function(z):\n",
      "    return 1 / (1 + np.exp(-z))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(BaseEstimator, ClassifierMixin):\n",
      "    def __init__(self):\n",
      "        pass\n",
      "\n",
      "    def l2_regularization(self, vector_):\n",
      "        return sum( vector_**2 )\n",
      "\n",
      "    def cost_function(self, theta_):\n",
      "        \"\"\"Error function\"\"\"\n",
      "        e = 1e-15   # For correction of -inf\n",
      "        y_ = self.y_train\n",
      "        X = self.X_train\n",
      "        \n",
      "        m = len(y_)\n",
      "        s = 0\n",
      "        for i in range(m):\n",
      "            g = logistic_function( np.dot( theta_, X[i, :] ) )\n",
      "            s += np.maximum(np.log(g), e)  + (1 - self.y_train[i]) * np.maximum(np.log(1-g), e) \n",
      "            #s += y_[i] * math.log(g) + (1 - y_[i]) * math.log(1 - g)\n",
      "        J = -(1/m) * s + self.alpha/(2*m)  * self.l2_regularization(theta_) \n",
      "        # Warning: Using minus. We can do max, but we need min.\n",
      "        return J\n",
      "\n",
      "    def grad_cost_function(self, theta_):\n",
      "        \"\"\"Gradient of error function\"\"\"\n",
      "        e = 1e-15\n",
      "        y_ = self.y_train\n",
      "        X = self.X_train\n",
      "        m = len(y_)\n",
      "        # s is a vector\\n\",\n",
      "        s_ = np.zeros_like(theta_) \n",
      "        for i in range(m):\n",
      "            g = logistic_function( np.dot( theta_, X[i, :]  ) )\n",
      "            s_ += g - y_[i] * X[i, :]\n",
      "        # Add regularization\n",
      "        s_ = -1/m * s_ + self.alpha/m * theta_\n",
      "        return s_\n",
      "    \n",
      "    def get_params(self, deep=True):\n",
      "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
      "        return {}\n",
      "\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)\n",
      "        return self\n",
      "    \n",
      "    def fit(self, X_train=None, y_train=None):\n",
      "        self.X_train = X_train\n",
      "        self.y_train = y_train\n",
      "        self.alpha = 0.1\n",
      "        \n",
      "        theta_ = np.ones(self.X_train.shape[1])  # Starting point\n",
      "        self.theta = fmin_bfgs(self.cost_function, theta_, fprime=self.grad_cost_function)  # , disp=False\n",
      "        return self.theta\n",
      "    \n",
      "        \n",
      "    def predict(self, X):\n",
      "        \"\"\"Predict 1 or 0 for a given vector x_\"\"\"\n",
      "        result = [logistic_function(np.dot(self.theta, x_)) for x_ in X]\n",
      "        return result\n",
      "    \n",
      "    def decision_function(self, X):\n",
      "        \"\"\"Predict 1 or 0 for a given vector x_\"\"\"\n",
      "        result = [logistic_function(np.dot(self.theta, x_)) for x_ in X]\n",
      "        return result\n",
      "    #result**y * (1 - result) ** (1 - y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing cost, grad, num. grad"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = X[:20]\n",
      "y_test = y[:20]\n",
      "LR = LogisticRegression()\n",
      "LR.fit(X_test, y_test)\n",
      "X_test.shape\n",
      "# Test cost function\n",
      "theta_test = np.ones(X_test.shape[1])\n",
      "c = LR.cost_function(theta_test)\n",
      "g = LR.grad_cost_function(theta_test).shape\n",
      "gr = check_grad(LR, theta_test)\n",
      "print(\"Cost:\", c)\n",
      "print(\"Grad:\", g)\n",
      "print(\"Grad diff:\", gr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cost: 0.2325\n",
        "Grad: (93,)\n",
        "Grad diff: 72.9297727268\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "One vs all"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import multiclass "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 3000\n",
      "LR2 = LogisticRegression()\n",
      "classifier = multiclass.OneVsRestClassifier(LR2)\n",
      "classifier.fit(X[:threshold], y[:threshold])\n",
      "classifier.predict(X[treshold-30:treshold])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Desired error not necessarily achieved due to precision loss.\n",
        "         Current function value: 0.001550\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2])"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "One vs one"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treshold = 3000\n",
      "LR3 = LogisticRegression()\n",
      "classifier = multiclass.OneVsOneClassifier(LR3).fit(X[:treshold], y[:treshold])\n",
      "classifier.fit(X_test, y_test).predict(X[2800:2830])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Desired error not necessarily achieved due to precision loss.\n",
        "         Current function value: 0.001550\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1])"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import log_loss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_cross_validation(X, y_, model):\n",
      "    k = 3\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(y_), n_folds=k, shuffle=True)\n",
      "    for train_index, test_index in kf:\n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y_[train_index], y_[test_index]\n",
      "        # Predict\n",
      "        model.fit(X_train, y_train)\n",
      "        P = model.predict(X_test) \n",
      "        # Evaluate\n",
      "        S += [llfun(y_test, P)]\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Integrated"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use integrated Logistic Regression and OneVsOneClassifier\n",
      "\n",
      "import random\n",
      "from sklearn import linear_model\n",
      "\n",
      "threshold = X.shape[0]\n",
      "X_try = X[:threshold]\n",
      "y_try = np.array([random.randint(0, 5) for i in range(X_try.shape[0])])\n",
      "# Integrated\n",
      "\n",
      "logreg = linear_model.LogisticRegression()\n",
      "classifier = multiclass.OneVsOneClassifier(logreg)\n",
      "one = my_cross_validation(X_try, y_try, classifier)\n",
      "\n",
      "logreg = linear_model.LogisticRegression()\n",
      "classifier = multiclass.OneVsRestClassifier(logreg)\n",
      "rest = my_cross_validation(X_try, y_try, classifier)\n",
      "\n",
      "print(\"OneVsOne\", one)\n",
      "print(\"OneVsAll\", rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OneVsOne -26.931596239\n",
        "OneVsAll -26.4300710352\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import ensemble\n",
      "\n",
      "threshold = X.shape[0]\n",
      "X_try = X[:threshold]\n",
      "y_try = np.array([random.randint(0, 5) for i in range(X_try.shape[0])])\n",
      "# Integrated\n",
      "\n",
      "classifier = ensemble.RandomForestClassifier()\n",
      "one = my_cross_validation(X_try, y_try, classifier)\n",
      "\n",
      "classifier = ensemble.RandomForestClassifier()\n",
      "rest = my_cross_validation(X_try, y_try, classifier)\n",
      "\n",
      "print(\"OneVsOne\", one)\n",
      "print(\"OneVsAll\", rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OneVsOne -19.8164979896\n",
        "OneVsAll -19.3122350966\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "My model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "threshold = X.shape[0]\n",
      "X_try = X[:threshold]\n",
      "y_try = np.array([random.randint(0, 5) for i in range(X_try.shape[0])])\n",
      "\n",
      "logreg = LogisticRegression()\n",
      "classifier = multiclass.OneVsOneClassifier(logreg)\n",
      "one = my_cross_validation(X_try, y_try, classifier)\n",
      "\n",
      "logreg = LogisticRegression()\n",
      "classifier = multiclass.OneVsRestClassifier(logreg)\n",
      "rest = my_cross_validation(X_try, y_try, classifier)\n",
      "\n",
      "print(\"OneVsOne\", one)\n",
      "print(\"OneVsAll\", rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Desired error not necessarily achieved due to precision loss.\n",
        "         Current function value: 0.000417\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000424\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000420\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000424\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000423\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000415\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000411\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000415\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000414\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000417\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000418\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000417\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000416\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000417\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000416\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000418\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000418\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000418\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000417\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000419\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000419\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000419\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000419\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000419\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000420\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000416\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000421\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000427\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000416\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000413\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000417\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000423\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000412\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000416\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000422\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000413\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000418\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000423\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000140\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000139\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000139\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000139\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000139\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000139\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.000139\n",
        "         Iterations: 0\n",
        "         Function evaluations: 26\n",
        "         Gradient evaluations: 14\n",
        "OneVsOne"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -51.6732748122\n",
        "OneVsAll 86.2108592305\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}