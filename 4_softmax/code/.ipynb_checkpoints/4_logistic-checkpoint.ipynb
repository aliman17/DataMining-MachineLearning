{
 "metadata": {
  "name": "",
  "signature": "sha256:74e4cdab3a2ed83323a1759c7d2f29c63c2c716de34264a93e21619d75243594"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usefull links\n",
      "- http://blog.smellthedata.com/2009/06/python-logistic-regression-with-l2.html\n",
      "- http://scikit-learn.org/stable/modules/multiclass.html\n",
      "- http://scikit-learn.org/stable/developers/#get-params-and-set-params\n",
      "- http://aimotion.blogspot.com/2011/11/machine-learning-with-python-logistic.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import random\n",
      "import math\n",
      "import scipy as sp\n",
      "from scipy.optimize.optimize import fmin_bfgs\n",
      "from sklearn.base import BaseEstimator, ClassifierMixin\n",
      "import random\n",
      "import warnings\n",
      "import random\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "from sklearn import linear_model\n",
      "from sklearn import multiclass\n",
      "from sklearn import ensemble\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load data and normalize it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm = preprocessing.Normalizer()\n",
      "X_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "X_train = norm.fit_transform(X_train)\n",
      "\n",
      "y_train = np.loadtxt(open(\"../data/train.csv\",\"rb\"),dtype=str,delimiter=\",\",skiprows=1, usecols=[94])\n",
      "y_train = np.array([int(c[-2]) for c in y_train])  # Parse classes from Class_1 into 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = np.loadtxt(open(\"../data/test.csv\",\"rb\"),delimiter=\",\",skiprows=1, usecols=range(1,94))\n",
      "X_test = norm.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    return 1 / (1 + np.exp(-z))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fix_me = lambda p: np.maximum(np.minimum(p, 1 - 1e-15), 1e-15)\n",
      "\n",
      "def J(X, y_, theta_, alpha):\n",
      "    m = len(y_)\n",
      "    h_ = np.array(list(map(sigmoid, X.dot(theta_))))\n",
      "    l2_reg = alpha / (2*m) * sum(theta_**2)\n",
      "    J = 1/m * (y_.dot(np.log(fix_me(h_))) + (1 - y_).dot(np.log(fix_me(1 - h_)))) - l2_reg\n",
      "    return -J\n",
      "        \n",
      "def Jgrad(X, y_, theta_, alpha):\n",
      "    m = len(y_)\n",
      "    h_ = np.array(list(map(sigmoid, X.dot(theta_))))\n",
      "    grad = 1/m * (y_ - h_).dot(X) - alpha/m * theta_\n",
      "    return -grad"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def numerical_grad(f, params, epsilon):\n",
      "    \"\"\"Method of finite differences, sanity check to see if our Jgrad is implemented correctly\"\"\"\n",
      "    num_grad = np.zeros_like(params)\n",
      "    perturb = np.zeros_like(params)\n",
      "    for i in range(params.size):\n",
      "        perturb[i] = epsilon\n",
      "        j1 = f(params + perturb)\n",
      "        j2 = f(params - perturb)\n",
      "        num_grad[i] = (j1 - j2) / (2. * epsilon)\n",
      "        perturb[i] = 0\n",
      "    return num_grad\n",
      "\n",
      "def check_grad(X, y_, theta_):\n",
      "    alpha = 2\n",
      "    f = lambda theta: J(X, y_, theta, alpha)\n",
      "    ag = Jgrad(X, y_, theta_, alpha)\n",
      "    ng = numerical_grad(f, theta_, 1e-5)\n",
      "    return np.sum((ag - ng)**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_grad(X_train[:100], y_train[:100], np.ones(X_train.shape[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "6.6894738904569158e-21"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def predict_proba(self, X):\n",
      "        X = np.column_stack((np.ones(X.shape[0]), X))  # za prosti clen\n",
      "        result = [sigmoid(np.dot(self.theta, x_)) for x_ in X]\n",
      "        return result\n",
      "    \n",
      "    def decision_function(self, X):\n",
      "        \"\"\"Predict 1 or 0 for a given vector x_\"\"\"\n",
      "        result = [sigmoid(np.dot(self.theta, x_)) for x_ in X]\n",
      "        return result\n",
      "    #result**y * (1 - result) ** (1 - y)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logloss(pred, act):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    x = np.array([p[a-1] for p, a in zip(pred, act)])\n",
      "    return -sum(np.log(x))/len(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate(act, prob):\n",
      "    return logloss(prob, act)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OneVsOne nima predict_proba!!! Bo treba drugace\n",
      "def my_cross_validation(X, y_, model):\n",
      "    k = 3\n",
      "    S = []\n",
      "    kf = cross_validation.KFold(len(y_), n_folds=k, shuffle=True)\n",
      "    for train_index, test_index in kf:\n",
      "        # Split\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y_[train_index], y_[test_index]\n",
      "        # Predict\n",
      "        model.fit(X_train, y_train)\n",
      "        P = model.predict_proba(X_test) \n",
      "        # Evaluate\n",
      "        S += [evaluate(y_test, P)]\n",
      "    S = np.array(S)\n",
      "    return(np.mean(S))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "LogisticRegression sklearn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "warnings.filterwarnings(\"ignore\")\n",
      "# Use integrated Logistic Regression and OneVsOneClassifier\n",
      "step = 10\n",
      "indices = list(range(0, X_train.shape[0], step))\n",
      "\n",
      "X = X_train[indices]\n",
      "y_ = y_train[indices]\n",
      "\n",
      "#logreg = linear_model.LogisticRegression()\n",
      "#classifier = multiclass.OneVsOneClassifier(logreg)\n",
      "#one = my_cross_validation(X, y_, classifier)\n",
      "\n",
      "logreg = linear_model.LogisticRegression()\n",
      "classifier = multiclass.OneVsRestClassifier(logreg)\n",
      "rest = my_cross_validation(X, y_, classifier)\n",
      "\n",
      "#print(\"OneVsOne\", one)\n",
      "print(\"OneVsAll\", rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OneVsAll 0.748689257764\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Random Forest sklearn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use integrated Logistic Regression and OneVsOneClassifier\n",
      "step = 10\n",
      "indices = list(range(0, X_train.shape[0], step))\n",
      "random.shuffle(indices)\n",
      "\n",
      "X = X_train[indices]\n",
      "y_ = y_train[indices]\n",
      "# Integrated\n",
      "\n",
      "classifier = ensemble.RandomForestClassifier()\n",
      "forest = my_cross_validation(X, y_, classifier)\n",
      "\n",
      "print(\"Random Forest\", forest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest 2.40158806259\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "My model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(BaseEstimator, ClassifierMixin):\n",
      "    def __init__(self, h=sigmoid, alpha=0.001):\n",
      "        self.h = h\n",
      "        self.alpha = alpha\n",
      "        \n",
      "    def get_params(self, deep=True):\n",
      "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
      "        return {}\n",
      "\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)\n",
      "        return self\n",
      "    \n",
      "    def fit(self, X, y_):     \n",
      "        X = np.column_stack((np.ones(len(y_)), X))  # za prosti clen\n",
      "        theta0_ = np.ones(X.shape[1])               # Starting point\n",
      "        self.theta = fmin_bfgs(lambda th_: J(X, y_, th_, self.alpha),\n",
      "                                    theta0_,\n",
      "                                    fprime=lambda th_: Jgrad(X, y_, th_, self.alpha),\n",
      "                                    maxiter=100 ) \n",
      "        return self\n",
      "    \n",
      "    def predict_proba(self, X):\n",
      "        if len(X.shape) == 2:  # za vec na enkrat\n",
      "            X = np.column_stack((np.ones(X.shape[0]), X))\n",
      "            pred = self.h(X.dot(self.theta))\n",
      "            pred = np.array(list(zip(1-pred, pred)))   # tole smo videli iz errorja ... potrebujemo pac n*2 matrix\n",
      "            return pred\n",
      "        else:  # za en vektor\n",
      "            X = np.hstack(([1], X))\n",
      "            pred = self.h(X.dot(self.theta))\n",
      "            return np.array([1-pred, pred])\n",
      "    def predict(self, X):\n",
      "        probs = self.predict_proba(X)\n",
      "        if len(probs.shape) == 2:\n",
      "            return np.array(list(map(np.argmax, probs)))  # najboljso predikcijo izberi\n",
      "        return np.array(np.argmax(probs))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "step = 100\n",
      "indices = list(range(0, X_train.shape[0], step))\n",
      "random.shuffle(indices)\n",
      "\n",
      "X = X_train[indices]\n",
      "y_ = y_train[indices]\n",
      "\n",
      "#logreg = LogisticRegression()\n",
      "#classifier = multiclass.OneVsOneClassifier(logreg)\n",
      "#one = my_cross_validation(X, y_, classifier)\n",
      "\n",
      "logreg = LogisticRegression()\n",
      "classifier = multiclass.OneVsRestClassifier(logreg)\n",
      "rest = my_cross_validation(X, y_, classifier)\n",
      "\n",
      "#print(\"OneVsOne\", one)\n",
      "print(\"OneVsAll\", rest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Maximum number of iterations has been exceeded.\n",
        "         Current function value: 0.019343\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.189184\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.143999\n",
        "         Iterations: 100\n",
        "         Function evaluations: 104\n",
        "         Gradient evaluations: 104\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.045766\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.003297\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.023181\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.019641\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.011814\n",
        "         Iterations: 100\n",
        "         Function evaluations: 103\n",
        "         Gradient evaluations: 103\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.014807\n",
        "         Iterations: 100\n",
        "         Function evaluations: 103\n",
        "         Gradient evaluations: 103\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.013496\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.189562\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.134817\n",
        "         Iterations: 100\n",
        "         Function evaluations: 104\n",
        "         Gradient evaluations: 104\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.052631\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.002099\n",
        "         Iterations: 100\n",
        "         Function evaluations: 104\n",
        "         Gradient evaluations: 104\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.017978\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.017556\n",
        "         Iterations: 100\n",
        "         Function evaluations: 103\n",
        "         Gradient evaluations: 103\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.012084\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.016624\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.011656\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.170174\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.126328\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.062865\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.002509\n",
        "         Iterations: 100\n",
        "         Function evaluations: 105\n",
        "         Gradient evaluations: 105\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.009635\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.020277\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.019301\n",
        "         Iterations: 100\n",
        "         Function evaluations: 103\n",
        "         Gradient evaluations: 103\n",
        "Warning: Maximum number of iterations has been exceeded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.014172\n",
        "         Iterations: 100\n",
        "         Function evaluations: 102\n",
        "         Gradient evaluations: 102\n",
        "OneVsAll 1.54710511264\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Predict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict(model, name):\n",
      "    global X_train, y_train, X_test\n",
      "    model.fit(X_train, y_train)\n",
      "    predicted = model.predict_proba(X_test)\n",
      "    \n",
      "    answer = np.matrix(predicted.astype(str))\n",
      "    ids = np.matrix(range(1, answer.shape[0]+1))\n",
      "    answer = np.hstack((ids.T.astype(str), answer))\n",
      "    answer = np.vstack((np.array([\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]), answer))\n",
      "    answer = answer.tolist()\n",
      "    answer = \"\\n\".join( [\",\".join(line) for line in answer] )\n",
      "    \n",
      "    fo = open(\"../results_logreg/\"+name+\".csv\", \"wt\")\n",
      "    fo.write(answer)\n",
      "    fo.close()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest = ensemble.RandomForestClassifier()\n",
      "logregR = multiclass.OneVsRestClassifier(linear_model.LogisticRegression())\n",
      "logregMy = multiclass.OneVsRestClassifier(LogisticRegression())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict(logregMy, 'logreg_1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}